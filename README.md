[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/pycorrector/blob/master/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/pycorrector/blob/master/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/pycorrector/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624) 

<div align="center">
  <a href="https://github.com/shibing624/pycorrector">
    <img src="https://github.com/shibing624/pycorrector/blob/master/docs/pycorrector.png" alt="Logo" height="156">
  </a>
</div>

-----------------

# pycorrector: useful python text correction toolkit
[![PyPI version](https://badge.fury.io/py/pycorrector.svg)](https://badge.fury.io/py/pycorrector)
[![Downloads](https://static.pepy.tech/badge/pycorrector)](https://pepy.tech/project/pycorrector)
[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/graphs/contributors)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_vesion](https://img.shields.io/badge/Python-3.6%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/issues)
[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#wechat-group)


**pycorrector**: ä¸­æ–‡æ–‡æœ¬çº é”™å·¥å…·ã€‚æ”¯æŒä¸­æ–‡éŸ³ä¼¼ã€å½¢ä¼¼ã€è¯­æ³•é”™è¯¯çº æ­£ï¼Œpython3å¼€å‘ã€‚

**pycorrector**å®ç°äº†Kenlmã€ConvSeq2Seqã€BERTã€MacBERTã€ELECTRAã€ERNIEã€Transformerç­‰å¤šç§æ¨¡å‹çš„æ–‡æœ¬çº é”™ï¼Œå¹¶åœ¨SigHANæ•°æ®é›†è¯„ä¼°å„æ¨¡å‹çš„æ•ˆæœã€‚

**Guide**

- [Question](#Question)
- [Solution](#Solution)
- [Evaluation](#Evaluation)
- [Install](#install)
- [Usage](#usage)
- [Deep Model Usage](#deep-model-usage)
- [Dataset](#Dataset)
- [Contact](#Contact)
- [Reference](#reference)

# Question

ä¸­æ–‡æ–‡æœ¬çº é”™ä»»åŠ¡ï¼Œå¸¸è§é”™è¯¯ç±»å‹ï¼š

<img src="docs/git_image/error_type.png" width="600" />

å½“ç„¶ï¼Œé’ˆå¯¹ä¸åŒä¸šåŠ¡åœºæ™¯ï¼Œè¿™äº›é—®é¢˜å¹¶ä¸ä¸€å®šå…¨éƒ¨å­˜åœ¨ï¼Œæ¯”å¦‚æ‹¼éŸ³è¾“å…¥æ³•ã€è¯­éŸ³è¯†åˆ«æ ¡å¯¹å…³æ³¨éŸ³ä¼¼é”™è¯¯ï¼›äº”ç¬”è¾“å…¥æ³•ã€OCRæ ¡å¯¹å…³æ³¨å½¢ä¼¼é”™è¯¯ï¼Œ
æœç´¢å¼•æ“queryçº é”™å…³æ³¨æ‰€æœ‰é”™è¯¯ç±»å‹ã€‚

æœ¬é¡¹ç›®é‡ç‚¹è§£å†³å…¶ä¸­çš„"éŸ³ä¼¼ã€å½¢å­—ã€è¯­æ³•ã€ä¸“åé”™è¯¯"ç­‰ç±»å‹ã€‚

# Solution

### è§„åˆ™çš„è§£å†³æ€è·¯
ä¾æ®è¯­è¨€æ¨¡å‹æ£€æµ‹é”™åˆ«å­—ä½ç½®ï¼Œé€šè¿‡æ‹¼éŸ³éŸ³ä¼¼ç‰¹å¾ã€ç¬”ç”»äº”ç¬”ç¼–è¾‘è·ç¦»ç‰¹å¾åŠè¯­è¨€æ¨¡å‹å›°æƒ‘åº¦ç‰¹å¾çº æ­£é”™åˆ«å­—ã€‚

1. ä¸­æ–‡çº é”™åˆ†ä¸ºä¸¤æ­¥èµ°ï¼Œç¬¬ä¸€æ­¥æ˜¯é”™è¯¯æ£€æµ‹ï¼Œç¬¬äºŒæ­¥æ˜¯é”™è¯¯çº æ­£ï¼›
2. é”™è¯¯æ£€æµ‹éƒ¨åˆ†å…ˆé€šè¿‡ç»“å·´ä¸­æ–‡åˆ†è¯å™¨åˆ‡è¯ï¼Œç”±äºå¥å­ä¸­å«æœ‰é”™åˆ«å­—ï¼Œæ‰€ä»¥åˆ‡è¯ç»“æœå¾€å¾€ä¼šæœ‰åˆ‡åˆ†é”™è¯¯çš„æƒ…å†µï¼Œè¿™æ ·ä»å­—ç²’åº¦å’Œè¯ç²’åº¦ä¸¤æ–¹é¢æ£€æµ‹é”™è¯¯ï¼Œ æ•´åˆè¿™ä¸¤ç§ç²’åº¦çš„ç–‘ä¼¼é”™è¯¯ç»“æœï¼Œå½¢æˆç–‘ä¼¼é”™è¯¯ä½ç½®å€™é€‰é›†ï¼›
3. é”™è¯¯çº æ­£éƒ¨åˆ†ï¼Œæ˜¯éå†æ‰€æœ‰çš„ç–‘ä¼¼é”™è¯¯ä½ç½®ï¼Œå¹¶ä½¿ç”¨éŸ³ä¼¼ã€å½¢ä¼¼è¯å…¸æ›¿æ¢é”™è¯¯ä½ç½®çš„è¯ï¼Œç„¶åé€šè¿‡è¯­è¨€æ¨¡å‹è®¡ç®—å¥å­å›°æƒ‘åº¦ï¼Œå¯¹æ‰€æœ‰å€™é€‰é›†ç»“æœæ¯”è¾ƒå¹¶æ’åºï¼Œå¾—åˆ°æœ€ä¼˜çº æ­£è¯ã€‚

### æ·±åº¦æ¨¡å‹çš„è§£å†³æ€è·¯

1. ç«¯åˆ°ç«¯çš„æ·±åº¦æ¨¡å‹å¯ä»¥é¿å…äººå·¥æå–ç‰¹å¾ï¼Œå‡å°‘äººå·¥å·¥ä½œé‡ï¼ŒRNNåºåˆ—æ¨¡å‹å¯¹æ–‡æœ¬ä»»åŠ¡æ‹Ÿåˆèƒ½åŠ›å¼ºï¼ŒRNN Attnåœ¨è‹±æ–‡æ–‡æœ¬çº é”™æ¯”èµ›ä¸­å–å¾—ç¬¬ä¸€åæˆç»©ï¼Œè¯æ˜åº”ç”¨æ•ˆæœä¸é”™ï¼›
2. CRFä¼šè®¡ç®—å…¨å±€æœ€ä¼˜è¾“å‡ºèŠ‚ç‚¹çš„æ¡ä»¶æ¦‚ç‡ï¼Œå¯¹å¥å­ä¸­ç‰¹å®šé”™è¯¯ç±»å‹çš„æ£€æµ‹ï¼Œä¼šæ ¹æ®æ•´å¥è¯åˆ¤å®šè¯¥é”™è¯¯ï¼Œé˜¿é‡Œå‚èµ›2016ä¸­æ–‡è¯­æ³•çº é”™ä»»åŠ¡å¹¶å–å¾—ç¬¬ä¸€åï¼Œè¯æ˜åº”ç”¨æ•ˆæœä¸é”™ï¼›
3. Seq2Seqæ¨¡å‹æ˜¯ä½¿ç”¨Encoder-Decoderç»“æ„è§£å†³åºåˆ—è½¬æ¢é—®é¢˜ï¼Œç›®å‰åœ¨åºåˆ—è½¬æ¢ä»»åŠ¡ä¸­ï¼ˆå¦‚æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆã€æ–‡æœ¬æ‘˜è¦ã€å›¾åƒæè¿°ï¼‰ä½¿ç”¨æœ€å¹¿æ³›ã€æ•ˆæœæœ€å¥½çš„æ¨¡å‹ä¹‹ä¸€ï¼›
4. BERT/ELECTRA/ERNIE/MacBERTç­‰é¢„è®­ç»ƒæ¨¡å‹å¼ºå¤§çš„è¯­è¨€è¡¨å¾èƒ½åŠ›ï¼Œå¯¹NLPå±Šå¸¦æ¥ç¿»å¤©è¦†åœ°çš„æ”¹å˜ï¼Œæµ·é‡çš„è®­ç»ƒæ•°æ®æ‹Ÿåˆçš„è¯­è¨€æ¨¡å‹æ•ˆæœæ— ä¸ä¼¦æ¯”ï¼ŒåŸºäºå…¶MASKæ©ç çš„ç‰¹å¾ï¼Œå¯ä»¥ç®€å•æ”¹é€ é¢„è®­ç»ƒæ¨¡å‹ç”¨äºçº é”™ï¼ŒåŠ ä¸Šfine-tuneï¼Œæ•ˆæœè½»æ¾è¾¾åˆ°æœ€ä¼˜ã€‚

PSï¼š

- [ä½œè€…çº é”™åˆ†äº«](https://github.com/shibing624/pycorrector/wiki/pycorrector%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E7%9B%B4%E6%92%AD%E5%88%86%E4%BA%AB)
- [ç½‘å‹æºç è§£è¯»](https://zhuanlan.zhihu.com/p/138981644)


# Feature

* [Kenlmæ¨¡å‹](pycorrector/corrector.py)ï¼šæœ¬é¡¹ç›®åŸºäºKenlmç»Ÿè®¡è¯­è¨€æ¨¡å‹å·¥å…·è®­ç»ƒäº†ä¸­æ–‡NGramè¯­è¨€æ¨¡å‹ï¼Œç»“åˆè§„åˆ™æ–¹æ³•ã€æ··æ·†é›†å¯ä»¥çº æ­£ä¸­æ–‡æ‹¼å†™é”™è¯¯ï¼Œæ–¹æ³•é€Ÿåº¦å¿«ï¼Œæ‰©å±•æ€§å¼ºï¼Œæ•ˆæœä¸€èˆ¬
* [MacBERTæ¨¡å‹](pycorrector/macbert)ã€æ¨èã€‘ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„MacBERT4CSCæ¨¡å‹ï¼Œæ¨¡å‹åŠ å…¥äº†é”™è¯¯æ£€æµ‹å’Œçº æ­£ç½‘ç»œï¼Œé€‚é…ä¸­æ–‡æ‹¼å†™çº é”™ä»»åŠ¡ï¼Œæ•ˆæœå¥½
* [Seq2Seqæ¨¡å‹](pycorrector/seq2seq)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„Seq2Seqæ¨¡å‹ã€ConvSeq2Seqæ¨¡å‹ï¼Œå…¶ä¸­ConvSeq2Seqåœ¨NLPCC-2018çš„ä¸­æ–‡è¯­æ³•çº é”™æ¯”èµ›ä¸­ï¼Œä½¿ç”¨å•æ¨¡å‹å¹¶å–å¾—ç¬¬ä¸‰åï¼Œå¯ä»¥å¹¶è¡Œè®­ç»ƒï¼Œæ¨¡å‹æ”¶æ•›å¿«ï¼Œæ•ˆæœä¸€èˆ¬
* [T5æ¨¡å‹](pycorrector/t5)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„T5æ¨¡å‹ï¼Œä½¿ç”¨Langboat/mengzi-t5-baseçš„é¢„è®­ç»ƒæ¨¡å‹fine-tuneä¸­æ–‡çº é”™æ•°æ®é›†ï¼Œæ¨¡å‹æ”¹é€ çš„æ½œåŠ›è¾ƒå¤§ï¼Œæ•ˆæœå¥½
* [BERTæ¨¡å‹](pycorrector/bert)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†åŸºäºåŸç”ŸBERTçš„fill-maskèƒ½åŠ›è¿›è¡Œçº æ­£é”™å­—çš„æ–¹æ³•ï¼Œæ•ˆæœå·®
* [ELECTRAæ¨¡å‹](pycorrector/electra)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†åŸºäºåŸç”ŸELECTRAçš„fill-maskèƒ½åŠ›è¿›è¡Œçº æ­£é”™å­—çš„æ–¹æ³•ï¼Œæ•ˆæœå·®
* [ERNIE_CSCæ¨¡å‹](pycorrector/ernie_csc)ï¼šæœ¬é¡¹ç›®åŸºäºPaddlePaddleå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„ERNIE_CSCæ¨¡å‹ï¼Œæ¨¡å‹åœ¨ERNIE-1.0ä¸Šfine-tuneï¼Œæ¨¡å‹ç»“æ„é€‚é…äº†ä¸­æ–‡æ‹¼å†™çº é”™ä»»åŠ¡ï¼Œæ•ˆæœå¥½
* [DeepContextæ¨¡å‹](pycorrector/deepcontext)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºæ–‡æœ¬çº é”™çš„DeepContextæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“æ„å‚è€ƒStanford Universityçš„NLCæ¨¡å‹ï¼Œ2014è‹±æ–‡çº é”™æ¯”èµ›å¾—ç¬¬ä¸€åï¼Œæ•ˆæœä¸€èˆ¬
* [Transformeræ¨¡å‹](pycorrector/transformer)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchçš„fairseqåº“è°ƒç ”äº†Transformeræ¨¡å‹ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™ï¼Œæ•ˆæœä¸€èˆ¬

# Demo

Official Demo: https://www.mulanai.com/product/corrector/

HuggingFace Demo: https://huggingface.co/spaces/shibing624/pycorrector

![](docs/hf.png)

run example: [examples/gradio_demo.py](examples/gradio_demo.py) to see the demo:
```shell
python examples/gradio_demo.py
```

# Evaluation

æä¾›è¯„ä¼°è„šæœ¬[examples/evaluate_models.py](./examples/evaluate_models.py)ï¼š

- ä½¿ç”¨sighan15è¯„ä¼°é›†ï¼šSIGHAN2015çš„æµ‹è¯•é›†[pycorrector/data/cn/sighan_2015/test.tsv](pycorrector/data/cn/sighan_2015/test.tsv)
  ï¼Œå·²ç»è½¬ä¸ºç®€ä½“ä¸­æ–‡ã€‚
- è¯„ä¼°æ ‡å‡†ï¼šçº é”™å‡†å¬ç‡ï¼Œé‡‡ç”¨ä¸¥æ ¼å¥å­ç²’åº¦ï¼ˆSentence Levelï¼‰è®¡ç®—æ–¹å¼ï¼ŒæŠŠæ¨¡å‹çº æ­£ä¹‹åçš„ä¸æ­£ç¡®å¥å­å®Œæˆç›¸åŒçš„è§†ä¸ºæ­£ç¡®ï¼Œå¦åˆ™ä¸ºé”™ã€‚

### è¯„ä¼°ç»“æœ
è¯„ä¼°æ•°æ®é›†ï¼šSIGHAN2015æµ‹è¯•é›†

GPUï¼šTesla V100ï¼Œæ˜¾å­˜ 32 GB

| Model Name      | Model Hub Link                                                                                                      | Backbone                 | GPU | Precision | Recall | F1 | QPS     |
|:----------------|:--------------------------------------------------------------------------------------------------------------------|:-------------------------|:----|:----------| :--| :--- |:--------|
| Kenlm           | -                                                                                                                   | kenlm                    | CPU | 0.6860    | 0.1529 | 0.2500 | 9       |
| BART-CSC        | [shibing624/bart4csc-base-chinese](https://huggingface.co/shibing624/bart4csc-base-chinese)                         | fnlp/bart-base-chinese   | GPU | 0.6984    | 0.6354 | 0.6654 | 58      |
| Mengzi-T5-CSC   | [shibing624/mengzi-t5-base-chinese-correction](https://huggingface.co/shibing624/mengzi-t5-base-chinese-correction) | mengzi-t5-base           | GPU | **0.8321**    | 0.6390 | 0.7229 | 214     |
| **MacBERT-CSC** | [shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)                   | hfl/chinese-macbert-base | GPU | 0.8254  | **0.7311** | **0.7754** | **224** |
| ChatGLM3-6B-CSC | [shibing624/chatglm3-6b-csc-chinese-lora](https://huggingface.co/shibing624/chatglm3-6b-csc-chinese-lora)           | chatglm3-6b              | GPU | 0.5263    | 0.4052 | 0.4579 | 4       |

### ç»“è®º

- ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹æ•ˆæœæœ€å¥½çš„æ˜¯**MacBert-CSC**ï¼Œæ¨¡å‹åç§°æ˜¯*shibing624/macbert4csc-base-chinese*ï¼Œhuggingface modelï¼š[shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)
- ä¸­æ–‡è¯­æ³•çº é”™æ¨¡å‹æ•ˆæœæœ€å¥½çš„æ˜¯**ChatGLM3-6B-CSC**ï¼Œæ¨¡å‹åç§°æ˜¯*shibing624/chatglm3-6b-csc-chinese-lora*ï¼Œhuggingface modelï¼š[shibing624/shibing624/chatglm3-6b-csc-chinese-lora](https://huggingface.co/shibing624/shibing624/chatglm3-6b-csc-chinese-lora)

# Install

```shell
pip install -U pycorrector
```

or

```shell
pip install -r requirements.txt

git clone https://github.com/shibing624/pycorrector.git
cd pycorrector
pip install --no-deps .
```


é€šè¿‡ä»¥ä¸Šä¸¤ç§æ–¹æ³•çš„ä»»ä½•ä¸€ç§å®Œæˆå®‰è£…éƒ½å¯ä»¥ã€‚å¦‚æœä¸æƒ³å®‰è£…ä¾èµ–åŒ…ï¼Œç›´æ¥ä½¿ç”¨dockeræ‹‰å–å®‰è£…å¥½çš„éƒ¨ç½²ç¯å¢ƒå³å¯ã€‚

#### å®‰è£…ä¾èµ–

* dockerä½¿ç”¨

```shell
docker run -it -v ~/.pycorrector:/root/.pycorrector shibing624/pycorrector:0.0.2
```

åç»­è°ƒç”¨pythonä½¿ç”¨å³å¯ï¼Œè¯¥é•œåƒå·²ç»å®‰è£…å¥½kenlmã€pycorrectorç­‰åŒ…ï¼Œå…·ä½“å‚è§[Dockerfile](Dockerfile)ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š

![docker](docs/git_image/docker.png)

* kenlmå®‰è£…

```
pip install kenlm
```

[å®‰è£…kenlm-wiki](https://github.com/shibing624/pycorrector/wiki/Install-kenlm)

* å…¶ä»–åº“åŒ…å®‰è£…

```
pip install -r requirements.txt
```

# Usage

### æ–‡æœ¬çº é”™

example: [examples/base_demo.py](examples/base_demo.py)

```python
import pycorrector

corrected_sent, detail = pycorrector.correct('å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å')
print(corrected_sent, detail)
```

output:

```
å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§ [('å› è¯¥', 'åº”è¯¥', 4, 6), ('å', 'åº§', 10, 11)]
```

> è§„åˆ™æ–¹æ³•é»˜è®¤ä¼šä»è·¯å¾„`~/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm`åŠ è½½kenlmè¯­è¨€æ¨¡å‹æ–‡ä»¶ï¼Œå¦‚æœæ£€æµ‹æ²¡æœ‰è¯¥æ–‡ä»¶ï¼Œ
åˆ™ç¨‹åºä¼šè‡ªåŠ¨è”ç½‘ä¸‹è½½ã€‚å½“ç„¶ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½[æ¨¡å‹æ–‡ä»¶(2.8G)](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm)å¹¶æ”¾ç½®äºè¯¥ä½ç½®ã€‚

### é”™è¯¯æ£€æµ‹

example: [examples/detect_demo.py](examples/detect_demo.py)

```python
import pycorrector

idx_errors = pycorrector.detect('å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å')
print(idx_errors)
```

output:

```
[['å› è¯¥', 4, 6, 'word'], ['å', 10, 11, 'char']]
```

> è¿”å›ç±»å‹æ˜¯`list`, `[error_word, begin_pos, end_pos, error_type]`ï¼Œ`pos`ç´¢å¼•ä½ç½®ä»¥0å¼€å§‹ã€‚

### æˆè¯­ã€ä¸“åçº é”™

example: [examples/proper_correct_demo.py](examples/proper_correct_demo.py)

```python
import sys

sys.path.append("..")
from pycorrector.proper_corrector import ProperCorrector

m = ProperCorrector()
x = [
    'æŠ¥åº”æ¥ä¸­è¿©æ¥',
    'ä»Šå¤©åœ¨æ‹¼å“†å“†ä¸Šä¹°äº†ç‚¹è‹¹æœ',
]

for i in x:
    print(i, ' -> ', m.proper_correct(i))
```

output:

```
æŠ¥åº”æ¥ä¸­è¿©æ¥  ->  ('æŠ¥åº”æ¥è¸µè€Œæ¥', [('æ¥ä¸­è¿©æ¥', 'æ¥è¸µè€Œæ¥', 2, 6)])
ä»Šå¤©åœ¨æ‹¼å“†å“†ä¸Šä¹°äº†ç‚¹è‹¹æœ  ->  ('ä»Šå¤©åœ¨æ‹¼å¤šå¤šä¸Šä¹°äº†ç‚¹è‹¹æœ', [('æ‹¼å“†å“†', 'æ‹¼å¤šå¤š', 3, 6)])
```


### è‡ªå®šä¹‰æ··æ·†é›†

é€šè¿‡åŠ è½½è‡ªå®šä¹‰æ··æ·†é›†ï¼Œæ”¯æŒç”¨æˆ·çº æ­£å·²çŸ¥çš„é”™è¯¯ï¼ŒåŒ…æ‹¬ä¸¤æ–¹é¢åŠŸèƒ½ï¼š1ï¼‰ã€æå‡å‡†ç¡®ç‡ã€‘è¯¯æ€åŠ ç™½ï¼›2ï¼‰ã€æå‡å¬å›ç‡ã€‘è¡¥å……å¬å›ã€‚

example: [examples/use_custom_confusion.py](examples/use_custom_confusion.py)

```python
import pycorrector

error_sentences = [
    'ä¹°iphonexï¼Œè¦å¤šå°‘é’±',
    'å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ æ——åº·',
]
for line in error_sentences:
    print(pycorrector.correct(line))

print('*' * 42)
pycorrector.set_custom_confusion_path_or_dict('./my_custom_confusion.txt')
for line in error_sentences:
    print(pycorrector.correct(line))
```

output:

```
('ä¹°iphonexï¼Œè¦å¤šå°‘é’±', [])   # "iphonex"æ¼å¬ï¼Œåº”è¯¥æ˜¯"iphoneX"
('å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ å¯åº·', [['å¼ æ——åº·', 'å¼ å¯åº·', 14, 17]]) # "å¼ å¯åº·"è¯¯æ€ï¼Œåº”è¯¥ä¸ç”¨çº 
*****************************************************
('ä¹°iphonexï¼Œè¦å¤šå°‘é’±', [['iphonex', 'iphoneX', 1, 8]])
('å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ æ——åº·', [])
```

> å…¶ä¸­`./my_custom_confusion.txt`çš„å†…å®¹æ ¼å¼å¦‚ä¸‹ï¼Œä»¥ç©ºæ ¼é—´éš”ï¼š

```
iPhoneå·® iPhoneX
å¼ æ——åº· å¼ æ——åº·
```

> æ··æ·†é›†åŠŸèƒ½åœ¨`correct`æ–¹æ³•ä¸­ç”Ÿæ•ˆï¼›
> `set_custom_confusion_dict`æ–¹æ³•çš„`path`å‚æ•°ä¸ºç”¨æˆ·è‡ªå®šä¹‰æ··æ·†é›†æ–‡ä»¶è·¯å¾„(str)æˆ–æ··æ·†é›†å­—å…¸(dict)ã€‚

### è‡ªå®šä¹‰è¯­è¨€æ¨¡å‹

é»˜è®¤æä¾›ä¸‹è½½å¹¶ä½¿ç”¨çš„kenlmè¯­è¨€æ¨¡å‹`zh_giga.no_cna_cmn.prune01244.klm`æ–‡ä»¶æ˜¯2.8Gï¼Œå†…å­˜å°çš„ç”µè„‘ä½¿ç”¨`pycorrector`ç¨‹åºå¯èƒ½ä¼šåƒåŠ›äº›ã€‚

æ”¯æŒç”¨æˆ·åŠ è½½è‡ªå·±è®­ç»ƒçš„kenlmè¯­è¨€æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨2014ç‰ˆäººæ°‘æ—¥æŠ¥æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œæ¨¡å‹å°ï¼ˆ140Mï¼‰ï¼Œå‡†ç¡®ç‡ç¨ä½ï¼Œæ¨¡å‹ä¸‹è½½åœ°å€ï¼š[people2014corpus_chars.klm(å¯†ç o5e9)](https://pan.baidu.com/s/1I2GElyHy_MAdek3YaziFYw)ã€‚

exampleï¼š[examples/load_custom_language_model.py](examples/load_custom_language_model.py)

```python
from pycorrector import Corrector
import os

pwd_path = os.path.abspath(os.path.dirname(__file__))
lm_path = os.path.join(pwd_path, './people2014corpus_chars.klm')
model = Corrector(language_model_path=lm_path)

corrected_sent, detail = model.correct('å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å')
print(corrected_sent, detail)
```

output:

```
å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§ [('å› è¯¥', 'åº”è¯¥', 4, 6), ('å', 'åº§', 10, 11)]
```

### è‹±æ–‡æ‹¼å†™çº é”™

æ”¯æŒè‹±æ–‡å•è¯çº§åˆ«çš„æ‹¼å†™é”™è¯¯çº æ­£ã€‚

exampleï¼š[examples/en_correct_demo.py](examples/en_correct_demo.py)

```python
import pycorrector

sent = "what happending? how to speling it, can you gorrect it?"
corrected_text, details = pycorrector.en_correct(sent)
print(sent, '=>', corrected_text)
print(details)
```

output:

```
what happending? how to speling it, can you gorrect it?
=> what happening? how to spelling it, can you correct it?
[('happending', 'happening', 5, 15), ('speling', 'spelling', 24, 31), ('gorrect', 'correct', 44, 51)]
```

### ä¸­æ–‡ç®€ç¹äº’æ¢

æ”¯æŒä¸­æ–‡ç¹ä½“åˆ°ç®€ä½“çš„è½¬æ¢ï¼Œå’Œç®€ä½“åˆ°ç¹ä½“çš„è½¬æ¢ã€‚

exampleï¼š[examples/traditional_simplified_chinese_demo.py](examples/traditional_simplified_chinese_demo.py)

```python
import pycorrector

traditional_sentence = 'æ†‚éƒçš„è‡ºç£çƒé¾œ'
simplified_sentence = pycorrector.traditional2simplified(traditional_sentence)
print(traditional_sentence, '=>', simplified_sentence)

simplified_sentence = 'å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ'
traditional_sentence = pycorrector.simplified2traditional(simplified_sentence)
print(simplified_sentence, '=>', traditional_sentence)
```

output:

```
æ†‚éƒçš„è‡ºç£çƒé¾œ => å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ
å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ => æ†‚éƒçš„è‡ºç£çƒé¾œ
```

### å‘½ä»¤è¡Œæ¨¡å¼

æ”¯æŒæ‰¹é‡æ–‡æœ¬çº é”™

```
python -m pycorrector -h
usage: __main__.py [-h] -o OUTPUT [-n] [-d] input

@description:

positional arguments:
  input                 the input file path, file encode need utf-8.

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT, --output OUTPUT
                        the output file path.
  -n, --no_char         disable char detect mode.
  -d, --detail          print detail info
```

caseï¼š

```
python -m pycorrector input.txt -o out.txt -n -d
```

> è¾“å…¥æ–‡ä»¶ï¼š`input.txt`ï¼›è¾“å‡ºæ–‡ä»¶ï¼š`out.txt `ï¼›å…³é—­å­—ç²’åº¦çº é”™ï¼›æ‰“å°è¯¦ç»†çº é”™ä¿¡æ¯ï¼›çº é”™ç»“æœä»¥`\t`é—´éš”

# Deep Model Usage

æœ¬é¡¹ç›®çš„åˆè¡·ä¹‹ä¸€æ˜¯æ¯”å¯¹ã€å…±äº«å„ç§æ–‡æœ¬çº é”™æ–¹æ³•ï¼ŒæŠ›ç –å¼•ç‰çš„ä½œç”¨ï¼Œå¦‚æœå¯¹å¤§å®¶åœ¨æ–‡æœ¬çº é”™ä»»åŠ¡ä¸Šæœ‰ä¸€ç‚¹å°å°çš„å¯å‘å°±æ˜¯æˆ‘è«å¤§çš„è£å¹¸äº†ã€‚

ä¸»è¦ä½¿ç”¨äº†å¤šç§æ·±åº¦æ¨¡å‹åº”ç”¨äºæ–‡æœ¬çº é”™ä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯å‰é¢`æ¨¡å‹`å°èŠ‚ä»‹ç»çš„[macbert](./pycorrector/macbert)ã€[seq2seq](./pycorrector/seq2seq)ã€
[bert](./pycorrector/bert)ã€[electra](./pycorrector/electra)ã€[transformer](./pycorrector/transformer)
ã€[ernie-csc](./pycorrector/ernie_csc)ã€[T5](./pycorrector/t5)ï¼Œå„æ¨¡å‹æ–¹æ³•å†…ç½®äº`pycorrector`æ–‡ä»¶å¤¹ä¸‹ï¼Œæœ‰`README.md`è¯¦ç»†æŒ‡å¯¼ï¼Œå„æ¨¡å‹å¯ç‹¬ç«‹è¿è¡Œï¼Œç›¸äº’ä¹‹é—´æ— ä¾èµ–ã€‚

- å®‰è£…ä¾èµ–

```
pip install -r requirements-dev.txt
```

## ä½¿ç”¨æ–¹æ³•

å„æ¨¡å‹å‡å¯ç‹¬ç«‹çš„é¢„å¤„ç†æ•°æ®ã€è®­ç»ƒã€é¢„æµ‹ã€‚

### **MacBert4cscæ¨¡å‹[æ¨è]**

åŸºäºMacBERTæ”¹å˜ç½‘ç»œç»“æ„çš„ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹ï¼Œæ¨¡å‹å·²ç»å¼€æºåœ¨HuggingFace Modelsï¼š[https://huggingface.co/shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)

æ¨¡å‹ç½‘ç»œç»“æ„ï¼š
- æœ¬é¡¹ç›®æ˜¯ MacBERT æ”¹å˜ç½‘ç»œç»“æ„çš„ä¸­æ–‡æ–‡æœ¬çº é”™æ¨¡å‹ï¼Œå¯æ”¯æŒ BERT ç±»æ¨¡å‹ä¸º backboneã€‚
- åœ¨åŸç”Ÿ BERT æ¨¡å‹ä¸Šè¿›è¡Œäº†é­”æ”¹ï¼Œè¿½åŠ äº†ä¸€ä¸ªå…¨è¿æ¥å±‚ä½œä¸ºé”™è¯¯æ£€æµ‹å³ [detection](https://github.com/shibing624/pycorrector/blob/c0f31222b7849c452cc1ec207c71e9954bd6ca08/pycorrector/macbert/macbert4csc.py#L18) ï¼Œ
MacBERT4CSC è®­ç»ƒæ—¶ç”¨ detection å±‚å’Œ correction å±‚çš„ loss åŠ æƒå¾—åˆ°æœ€ç»ˆçš„ lossã€‚é¢„æµ‹æ—¶ç”¨ BERT MLM çš„ correction æƒé‡å³å¯ã€‚ 

![macbert_network](https://github.com/shibing624/pycorrector/blob/master/docs/git_image/macbert_network.jpg)

è¯¦ç»†æ•™ç¨‹å‚è€ƒ[pycorrector/macbert/README.md](./pycorrector/macbert/README.md)

exampleï¼š[examples/macbert_demo.py](examples/macbert_demo.py)
#### ä½¿ç”¨pycorrectorè°ƒç”¨çº é”™ï¼š

```python
import sys

sys.path.append("..")
from pycorrector.macbert.macbert_corrector import MacBertCorrector

if __name__ == '__main__':
    error_sentences = [
        'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ— ',
        'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å',
        'æœºä¸ƒå­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†é‡æœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥',
        'ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š',
        'æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰æ˜çš„æ¸”ç±³ä¹‹ä¹¡',
    ]

    m = MacBertCorrector("shibing624/macbert4csc-base-chinese")
    for line in error_sentences:
        correct_sent, err = m.macbert_correct(line)
        print("query:{} => {}, err:{}".format(line, correct_sent, err))
```

outputï¼š

```bash
query:çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ—  => çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³èˆ, err:[('æ— ', 'èˆ', 14, 15)]
query:å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å => å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©å, err:[('å› ', 'åº”', 4, 5)]
query:æœºä¸ƒå­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†é‡æœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥ => æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸæœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥, err:[('ä¸ƒ', 'å™¨', 1, 2), ('é‡', 'åŸŸ', 10, 11)]
query:ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š => ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š, err:[]
query:æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰æ˜çš„æ¸”ç±³ä¹‹ä¹¡ => æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰åçš„æ¸”ç±³ä¹‹ä¹¡, err:[('æ˜', 'å', 6, 7)]
```

#### ä½¿ç”¨åŸç”Ÿtransformersåº“è°ƒç”¨çº é”™ï¼š

```python
import operator
import torch
from transformers import BertTokenizerFast, BertForMaskedLM
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

tokenizer = BertTokenizerFast.from_pretrained("shibing624/macbert4csc-base-chinese")
model = BertForMaskedLM.from_pretrained("shibing624/macbert4csc-base-chinese")
model.to(device)

texts = ["ä»Šå¤©æ–°æƒ…å¾ˆå¥½", "ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å¿ƒã€‚"]

text_tokens = tokenizer(texts, padding=True, return_tensors='pt').to(device)
with torch.no_grad():
    outputs = model(**text_tokens)

def get_errors(corrected_text, origin_text):
    sub_details = []
    for i, ori_char in enumerate(origin_text):
        if ori_char in [' ', 'â€œ', 'â€', 'â€˜', 'â€™', '\n', 'â€¦', 'â€”', 'æ“¤']:
            # add unk word
            corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]
            continue
        if i >= len(corrected_text):
            break
        if ori_char != corrected_text[i]:
            if ori_char.lower() == corrected_text[i]:
                # pass english upper char
                corrected_text = corrected_text[:i] + ori_char + corrected_text[i + 1:]
                continue
            sub_details.append((ori_char, corrected_text[i], i, i + 1))
    sub_details = sorted(sub_details, key=operator.itemgetter(2))
    return corrected_text, sub_details

result = []
for ids, (i, text) in zip(outputs.logits, enumerate(texts)):
    _text = tokenizer.decode((torch.argmax(ids, dim=-1) * text_tokens.attention_mask[i]),
                             skip_special_tokens=True).replace(' ', '')
    corrected_text, details = get_errors(_text, text)
    print(text, ' => ', corrected_text, details)
    result.append((corrected_text, details))
print(result)
```

output:

```shell
ä»Šå¤©æ–°æƒ…å¾ˆå¥½  =>  ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ [('æ–°', 'å¿ƒ', 2, 3)]
ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å¿ƒã€‚  =>  ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å…´ã€‚ [('å¿ƒ', 'å…´', 15, 16)]
```

æ¨¡å‹æ–‡ä»¶ï¼š

```
macbert4csc-base-chinese
    â”œâ”€â”€ config.json
    â”œâ”€â”€ added_tokens.json
    â”œâ”€â”€ pytorch_model.bin
    â”œâ”€â”€ special_tokens_map.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ vocab.txt
```

### ErnieCSCæ¨¡å‹

åŸºäºERNIEçš„ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹ï¼Œæ¨¡å‹å·²ç»å¼€æºåœ¨[PaddleNLP](https://bj.bcebos.com/paddlenlp/taskflow/text_correction/csc-ernie-1.0/csc-ernie-1.0.pdparams)çš„
æ¨¡å‹åº“ä¸­[https://bj.bcebos.com/paddlenlp/taskflow/text_correction/csc-ernie-1.0/csc-ernie-1.0.pdparams](https://bj.bcebos.com/paddlenlp/taskflow/text_correction/csc-ernie-1.0/csc-ernie-1.0.pdparams)ã€‚

æ¨¡å‹ç½‘ç»œç»“æ„ï¼š

<img src="https://user-images.githubusercontent.com/10826371/131974040-fc84ec04-566f-4310-9839-862bfb27172e.png" width="500" />

è¯¦ç»†æ•™ç¨‹å‚è€ƒ[pycorrector/ernie_csc/README.md](./pycorrector/ernie_csc/README.md)

exampleï¼š[examples/ernie_csc_demo.py](examples/ernie_csc_demo.py)

#### ä½¿ç”¨pycorrectorè°ƒç”¨çº é”™ï¼š

```python

from pycorrector.ernie_csc.ernie_csc_corrector import ErnieCSCCorrector

if __name__ == '__main__':
    error_sentences = [
        'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ— ',
        'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å',
        'æœºä¸ƒå­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†é‡æœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥',
        'ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š',
        'æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰æ˜çš„æ¸”ç±³ä¹‹ä¹¡',
    ]
    corrector = ErnieCSCCorrector("csc-ernie-1.0")
    for line in error_sentences:
        result = corrector.ernie_csc_correct(line)[0]
        print("query:{} => {}, err:{}".format(line, result['target'], result['errors']))
```

output:

```bash

query:çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ—  => çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³èˆ, err:[{'position': 14, 'correction': {'æ— ': 'èˆ'}}]
query:å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å => å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§, err:[{'position': 4, 'correction': {'å› ': 'åº”'}}, {'position': 10, 'correction': {'å': 'åº§'}}]
query:æœºä¸ƒå­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†é‡æœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥ => æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸæœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥, err:[{'position': 1, 'correction': {'ä¸ƒ': 'å™¨'}}, {'position': 10, 'correction': {'é‡': 'åŸŸ'}}]
query:ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š => ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š, err:[]
query:æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰æ˜çš„æ¸”ç±³ä¹‹ä¹¡ => æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰åçš„æ¸”ç±³ä¹‹ä¹¡, err:[{'position': 6, 'correction': {'æ˜': 'å'}}]

```

#### ä½¿ç”¨PaddleNLPåº“è°ƒç”¨çº é”™ï¼š

å¯ä»¥ä½¿ç”¨PaddleNLPæä¾›çš„Taskflowå·¥å…·æ¥å¯¹è¾“å…¥çš„æ–‡æœ¬è¿›è¡Œä¸€é”®çº é”™ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹:

```python

from paddlenlp import Taskflow

text_correction = Taskflow("text_correction")
text_correction('é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½æœè‘—æˆåŠŸä¹‹è·¯å‰è¿›ã€‚')
text_correction('äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ æ‹™å£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚')

```

output:

```shell

[{'source': 'é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½æœè‘—æˆåŠŸä¹‹è·¯å‰è¿›ã€‚',
    'target': 'é‡åˆ°é€†å¢ƒæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½æœè‘—æˆåŠŸä¹‹è·¯å‰è¿›ã€‚',
    'errors': [{'position': 3, 'correction': {'ç«Ÿ': 'å¢ƒ'}}]}]

[{'source': 'äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ æ‹™å£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚',
    'target': 'äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ èŒå£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚',
    'errors': [{'position': 18, 'correction': {'æ‹™': 'èŒ'}}]}]

```

### Bartæ¨¡å‹

```python
from transformers import BertTokenizerFast
from textgen import BartSeq2SeqModel

tokenizer = BertTokenizerFast.from_pretrained('shibing624/bart4csc-base-chinese')
model = BartSeq2SeqModel(
    encoder_type='bart',
    encoder_decoder_type='bart',
    encoder_decoder_name='shibing624/bart4csc-base-chinese',
    tokenizer=tokenizer,
    args={"max_length": 128, "eval_batch_size": 128})
sentences = ["å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å"]
print(model.predict(sentences))
```


output:

```shell
['å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§']
```

å¦‚æœéœ€è¦è®­ç»ƒBartæ¨¡å‹ï¼Œè¯·å‚è€ƒ https://github.com/shibing624/textgen/blob/main/examples/seq2seq/training_bartseq2seq_zh_demo.py

#### Release models

åŸºäºSIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†è®­ç»ƒçš„Bartæ¨¡å‹ï¼Œå·²ç»releaseåˆ°HuggingFace Models:

- BARTæ¨¡å‹ï¼šæ¨¡å‹å·²ç»å¼€æºåœ¨HuggingFace Modelsï¼š[https://huggingface.co/shibing624/bart4csc-base-chinese](https://huggingface.co/shibing624/bart4csc-base-chinese)

# Dataset

| æ•°æ®é›†                          | è¯­æ–™ |                                                                                ä¸‹è½½é“¾æ¥                                                                                 | å‹ç¼©åŒ…å¤§å° |
|:-----------------------------| :--------- |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----:|
| **`SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†`** | SIGHAN+Wang271K(27ä¸‡æ¡) |               [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç 01b9ï¼‰](https://pan.baidu.com/s/1BV5tr9eONZCI0wERFvr0gQ) <br/> [shibing624/CSC](https://huggingface.co/datasets/shibing624/CSC)                | 106M  |
| **`åŸå§‹SIGHANæ•°æ®é›†`**            | SIGHAN13 14 15 |                                                      [å®˜æ–¹csc.html](http://nlp.ee.ncu.edu.tw/resource/csc.html)                                                       | 339K  |
| **`åŸå§‹Wang271Kæ•°æ®é›†`**          | Wang271K |                   [Automatic-Corpus-Generation dimmywangæä¾›](https://github.com/wdimmy/Automatic-Corpus-Generation/blob/master/corpus/train.sgml)                    |  93M  |
| **`äººæ°‘æ—¥æŠ¥2014ç‰ˆè¯­æ–™`**            | äººæ°‘æ—¥æŠ¥2014ç‰ˆ |                                    [é£ä¹¦ï¼ˆå¯†ç cHcuï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcnKpildqIseq1D4IrLwlir7c?from=from_qr_code)                                    | 383M  |
| **`NLPCC 2018 GECå®˜æ–¹æ•°æ®é›†`**    | NLPCC2018-GEC |                                        [å®˜æ–¹trainingdata](http://tcci.ccf.org.cn/conference/2018/dldoc/trainingdata02.tar.gz)                                         | 114M  |
| **`NLPCC 2018+HSKç†Ÿè¯­æ–™`**      | nlpcc2018+hsk+CGED | [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç m6fgï¼‰](https://pan.baidu.com/s/1BkDru60nQXaDVLRSr7ktfA) <br/> [é£ä¹¦ï¼ˆå¯†ç gl9yï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcnudJgRs5GEMhZwe77YGTQfc?from=from_qr_code) | 215M  |
| **`NLPCC 2018+HSKåŸå§‹è¯­æ–™`**     | HSK+Lang8 | [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç n31jï¼‰](https://pan.baidu.com/s/1DaOX89uL1JRaZclfrV9C0g) <br/> [é£ä¹¦ï¼ˆå¯†ç Q9LHï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcntebW3NI6OAaqzDUXlZHoDb?from=from_qr_code) |  81M  |
| **`ä¸­æ–‡çº é”™æ¯”èµ›æ•°æ®æ±‡æ€»`**             | Chinese Text Correctionï¼ˆCTCï¼‰ |                                                     [ä¸­æ–‡çº é”™æ±‡æ€»æ•°æ®é›†ï¼ˆå¤©æ± ï¼‰](https://tianchi.aliyun.com/dataset/138195)                                                      |   -   |
| **`NLPCC 2023ä¸­æ–‡è¯­æ³•çº é”™æ•°æ®é›†`**    | NLPCC 2023 Sharedtask1 |                          [Task 1: Chinese Grammatical Error Correctionï¼ˆTraining Setï¼‰](http://tcci.ccf.org.cn/conference/2023/taskdata.php)                          | 125M  |



è¯´æ˜ï¼š

- SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†(27ä¸‡æ¡)ï¼Œæ˜¯é€šè¿‡åŸå§‹SIGHAN13ã€14ã€15å¹´æ•°æ®é›†å’ŒWang271Kæ•°æ®é›†æ ¼å¼è½¬åŒ–åå¾—åˆ°ï¼Œjsonæ ¼å¼ï¼Œå¸¦é”™è¯¯å­—ç¬¦ä½ç½®ä¿¡æ¯ï¼ŒSIGHANä¸ºtest.jsonï¼Œ
  macbert4cscæ¨¡å‹è®­ç»ƒå¯ä»¥ç›´æ¥ç”¨è¯¥æ•°æ®é›†å¤ç°paperå‡†å¬ç»“æœï¼Œè¯¦è§[pycorrector/macbert/README.md](pycorrector/macbert/README.md)ã€‚
- NLPCC 2018 GECå®˜æ–¹æ•°æ®é›†[NLPCC2018-GEC](http://tcci.ccf.org.cn/conference/2018/taskdata.php)ï¼Œ
  è®­ç»ƒé›†[trainingdata](http://tcci.ccf.org.cn/conference/2018/dldoc/trainingdata02.tar.gz)[è§£å‹å114.5MB]ï¼Œè¯¥æ•°æ®æ ¼å¼æ˜¯åŸå§‹æ–‡æœ¬ï¼Œæœªåšåˆ‡è¯å¤„ç†ã€‚
- æ±‰è¯­æ°´å¹³è€ƒè¯•ï¼ˆHSKï¼‰å’Œlang8åŸå§‹å¹³è¡Œè¯­æ–™[HSK+Lang8][ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç n31jï¼‰](https://pan.baidu.com/s/1DaOX89uL1JRaZclfrV9C0g)ï¼Œè¯¥æ•°æ®é›†å·²ç»åˆ‡è¯ï¼Œå¯ç”¨ä½œæ•°æ®æ‰©å¢ã€‚
- NLPCC 2018 + HSK + CGED16ã€17ã€18çš„æ•°æ®ï¼Œç»è¿‡ä»¥å­—åˆ‡åˆ†ï¼Œç¹ä½“è½¬ç®€ä½“ï¼Œæ‰“ä¹±æ•°æ®é¡ºåºçš„é¢„å¤„ç†åï¼Œç”Ÿæˆç”¨äºçº é”™çš„ç†Ÿè¯­æ–™(nlpcc2018+hsk)
  ï¼Œ[ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç :m6fgï¼‰](https://pan.baidu.com/s/1BkDru60nQXaDVLRSr7ktfA) [130ä¸‡å¯¹å¥å­ï¼Œ215MB]

SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†ï¼Œæ•°æ®æ ¼å¼ï¼š
```json
[
    {
        "id": "B2-4029-3",
        "original_text": "æ™šé—´ä¼šå¬åˆ°å—“éŸ³ï¼Œç™½å¤©çš„æ—¶å€™å¤§å®¶éƒ½ä¸ä¼šå¤ªåœ¨æ„ï¼Œä½†æ˜¯åœ¨ç¡è§‰çš„æ—¶å€™è¿™å—“éŸ³æˆä¸ºå¤§å®¶çš„æ¶æ¢¦ã€‚",
        "wrong_ids": [
            5,
            31
        ],
        "correct_text": "æ™šé—´ä¼šå¬åˆ°å™ªéŸ³ï¼Œç™½å¤©çš„æ—¶å€™å¤§å®¶éƒ½ä¸ä¼šå¤ªåœ¨æ„ï¼Œä½†æ˜¯åœ¨ç¡è§‰çš„æ—¶å€™è¿™å™ªéŸ³æˆä¸ºå¤§å®¶çš„æ¶æ¢¦ã€‚"
    }
]
```

å­—æ®µè§£é‡Šï¼š
- idï¼šå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œæ— æ„ä¹‰
- original_text: åŸå§‹é”™è¯¯æ–‡æœ¬
- wrong_idsï¼š é”™è¯¯å­—çš„ä½ç½®ï¼Œä»0å¼€å§‹
- correct_text: çº æ­£åçš„æ–‡æœ¬

#### è‡ªæœ‰æ•°æ®é›†

å¯ä»¥ä½¿ç”¨è‡ªå·±æ•°æ®é›†è®­ç»ƒçº é”™æ¨¡å‹ï¼ŒæŠŠè‡ªå·±æ•°æ®é›†æ ‡æ³¨å¥½ï¼Œä¿å­˜ä¸ºè·Ÿè®­ç»ƒæ ·æœ¬é›†ä¸€æ ·çš„jsonæ ¼å¼ï¼Œç„¶ååŠ è½½æ•°æ®è®­ç»ƒæ¨¡å‹å³å¯ã€‚

1. å·²æœ‰å¤§é‡ä¸šåŠ¡ç›¸å…³é”™è¯¯æ ·æœ¬ï¼Œä¸»è¦æ ‡æ³¨é”™è¯¯ä½ç½®ï¼ˆwrong_idsï¼‰å’Œçº é”™åçš„å¥å­(correct_text)
2. æ²¡æœ‰ç°æˆçš„é”™è¯¯æ ·æœ¬ï¼Œå¯ä»¥å†™è„šæœ¬ç”Ÿæˆé”™è¯¯æ ·æœ¬ï¼ˆoriginal_textï¼‰ï¼Œæ ¹æ®éŸ³ä¼¼ã€å½¢ä¼¼ç­‰ç‰¹å¾æŠŠæ­£ç¡®å¥å­çš„æŒ‡å®šä½ç½®ï¼ˆwrong_idsï¼‰å­—ç¬¦æ”¹ä¸ºé”™å­—ï¼Œé™„ä¸Š
ç¬¬ä¸‰æ–¹åŒéŸ³å­—ç”Ÿæˆè„šæœ¬[åŒéŸ³è¯æ›¿æ¢](https://github.com/dongrixinyu/JioNLP/wiki/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3#%E5%90%8C%E9%9F%B3%E8%AF%8D%E6%9B%BF%E6%8D%A2)


## Language Model

[ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ-wiki](https://github.com/shibing624/pycorrector/wiki/%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86)

è¯­è¨€æ¨¡å‹å¯¹äºçº é”™æ­¥éª¤è‡³å…³é‡è¦ï¼Œå½“å‰é»˜è®¤ä½¿ç”¨çš„æ˜¯ä»åƒå…†ä¸­æ–‡æ–‡æœ¬è®­ç»ƒçš„ä¸­æ–‡è¯­è¨€æ¨¡å‹[zh_giga.no_cna_cmn.prune01244.klm(2.8G)](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm)ï¼Œ
æä¾›äººæ°‘æ—¥æŠ¥2014ç‰ˆè¯­æ–™è®­ç»ƒå¾—åˆ°çš„è½»é‡ç‰ˆè¯­è¨€æ¨¡å‹[people2014corpus_chars.klm(å¯†ç o5e9)](https://pan.baidu.com/s/1I2GElyHy_MAdek3YaziFYw)ã€‚

å¤§å®¶å¯ä»¥ç”¨ä¸­æ–‡ç»´åŸºï¼ˆç¹ä½“è½¬ç®€ä½“ï¼Œpycorrector.utils.text_utilsä¸‹æœ‰æ­¤åŠŸèƒ½ï¼‰ç­‰è¯­æ–™æ•°æ®è®­ç»ƒé€šç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ç”¨ä¸“ä¸šé¢†åŸŸè¯­æ–™è®­ç»ƒæ›´ä¸“ç”¨çš„è¯­è¨€æ¨¡å‹ã€‚æ›´é€‚ç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œå¯¹äºçº é”™æ•ˆæœä¼šæœ‰æ¯”è¾ƒå¥½çš„æå‡ã€‚

1. kenlmè¯­è¨€æ¨¡å‹è®­ç»ƒå·¥å…·çš„ä½¿ç”¨ï¼Œè¯·è§åšå®¢ï¼šhttp://blog.csdn.net/mingzai624/article/details/79560063
2. é™„ä¸Šè®­ç»ƒè¯­æ–™<äººæ°‘æ—¥æŠ¥2014ç‰ˆç†Ÿè¯­æ–™>ï¼ŒåŒ…æ‹¬ï¼š 1ï¼‰æ ‡å‡†äººå·¥åˆ‡è¯åŠè¯æ€§æ•°æ®people2014.tar.gzï¼Œ 2ï¼‰æœªåˆ‡è¯æ–‡æœ¬æ•°æ®people2014_words.txtï¼Œ
   3ï¼‰kenlmè®­ç»ƒå­—ç²’åº¦è¯­è¨€æ¨¡å‹æ–‡ä»¶åŠå…¶äºŒè¿›åˆ¶æ–‡ä»¶people2014corpus_chars.arps/klmï¼Œ 4ï¼‰kenlmè¯ç²’åº¦è¯­è¨€æ¨¡å‹æ–‡ä»¶åŠå…¶äºŒè¿›åˆ¶æ–‡ä»¶people2014corpus_words.arps/klmã€‚

å°Šé‡ç‰ˆæƒï¼Œä¼ æ’­è¯·æ³¨æ˜å‡ºå¤„ã€‚


# Contact

- Github Issue(å»ºè®®)ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/issues)
- Github discussionsï¼šæ¬¢è¿åˆ°è®¨è®ºåŒº[![GitHub discussions](https://img.shields.io/github/discussions/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/discussions)çŒæ°´ï¼ˆä¸ä¼šæ‰“æ‰°å¼€å‘è€…ï¼‰ï¼Œå…¬å¼€äº¤æµçº é”™æŠ€æœ¯å’Œé—®é¢˜
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼šåŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624*, è¿›Python-NLPäº¤æµç¾¤ï¼Œå¤‡æ³¨ï¼š*å§“å-å…¬å¸å-NLP*


<img src="https://github.com/shibing624/pycorrector/blob/master/docs/git_image/wechat.jpeg" width="200" />

# Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†pycorrectorï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

APA:
```latex
Xu, M. Pycorrector: Text error correction tool (Version 0.4.2) [Computer software]. https://github.com/shibing624/pycorrector
```

BibTeX:
```latex
@misc{Xu_Pycorrector_Text_error,
  title={Pycorrector: Text error correction tool},
  author={Ming Xu},
  year={2021},
  howpublished={\url{https://github.com/shibing624/pycorrector}},
}
```



# License

pycorrector çš„æˆæƒåè®®ä¸º **Apache License 2.0**ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ pycorrectorçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚

# Contribute

é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

- åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
- ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚

# Reference

* [åŸºäºæ–‡æ³•æ¨¡å‹çš„ä¸­æ–‡çº é”™ç³»ç»Ÿ](https://blog.csdn.net/mingzai624/article/details/82390382)
* [Norvigâ€™s spelling corrector](http://norvig.com/spell-correct.html)
* [Chinese Spelling Error Detection and Correction Based on Language Model, Pronunciation, and Shape[Yu, 2013]](http://www.aclweb.org/anthology/W/W14/W14-6835.pdf)
* [Chinese Spelling Checker Based on Statistical Machine Translation[Chiu, 2013]](http://www.aclweb.org/anthology/O/O13/O13-1005.pdf)
* [Chinese Word Spelling Correction Based on Rule Induction[yeh, 2014]](http://aclweb.org/anthology/W14-6822)
* [Neural Language Correction with Character-Based Attention[Ziang Xie, 2016]](https://arxiv.org/pdf/1603.09727.pdf)
* [Chinese Spelling Check System Based on Tri-gram Model[Qiang Huang, 2014]](http://www.anthology.aclweb.org/W/W14/W14-6827.pdf)
* [Neural Abstractive Text Summarization with Sequence-to-Sequence Models[Tian Shi, 2018]](https://arxiv.org/abs/1812.02303)
* [åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ ¡å¯¹ç ”ç©¶ä¸å®ç°[æ¨å®—éœ–, 2019]](https://github.com/shibing624/pycorrector/blob/master/docs/åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ ¡å¯¹ç ”ç©¶ä¸å®ç°.pdf)
* [A Sequence to Sequence Learning for Chinese Grammatical Error Correction[Hongkai Ren, 2018]](https://link.springer.com/chapter/10.1007/978-3-319-99501-4_36)
* [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)
* [Revisiting Pre-trained Models for Chinese Natural Language Processing](https://arxiv.org/abs/2004.13922)
* Ruiqing Zhang, Chao Pang et al. "Correcting Chinese Spelling Errors with Phonetic Pre-training", ACL, 2021
* DingminWang et al. "A Hybrid Approach to Automatic Corpus Generation for Chinese Spelling Check", EMNLP, 2018
