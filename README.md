[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/pycorrector/blob/master/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/pycorrector/blob/master/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/pycorrector/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624) 

<div align="center">
  <a href="https://github.com/shibing624/pycorrector">
    <img src="https://github.com/shibing624/pycorrector/blob/master/docs/pycorrector.png" alt="Logo" height="156">
  </a>
</div>

-----------------

# pycorrector: useful python text correction toolkit
[![PyPI version](https://badge.fury.io/py/pycorrector.svg)](https://badge.fury.io/py/pycorrector)
[![Downloads](https://static.pepy.tech/badge/pycorrector)](https://pepy.tech/project/pycorrector)
[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/graphs/contributors)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_vesion](https://img.shields.io/badge/Python-3.6%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/issues)
[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#wechat-group)


**pycorrector**: ä¸­æ–‡æ–‡æœ¬çº é”™å·¥å…·ã€‚æ”¯æŒä¸­æ–‡éŸ³ä¼¼ã€å½¢ä¼¼ã€è¯­æ³•é”™è¯¯çº æ­£ï¼Œpython3å¼€å‘ã€‚

**pycorrector**å®ç°äº†Kenlmã€ConvSeq2Seqã€BERTã€MacBERTã€ELECTRAã€ERNIEã€Transformerç­‰å¤šç§æ¨¡å‹çš„æ–‡æœ¬çº é”™ï¼Œå¹¶åœ¨SigHANæ•°æ®é›†è¯„ä¼°å„æ¨¡å‹çš„æ•ˆæœã€‚

**Guide**

- [Features](#Features)
- [Evaluation](#Evaluation)
- [Install](#install)
- [Usage](#usage)
- [Deep Model Usage](#deep-model-usage)
- [ContextDataset](#Dataset)
- [Contact](#Contact)
- [Reference](#reference)

# Question

ä¸­æ–‡æ–‡æœ¬çº é”™ä»»åŠ¡ï¼Œå¸¸è§é”™è¯¯ç±»å‹ï¼š

<img src="https://github.com/shibing624/pycorrector/blob/master/docs/git_image/error_type.png" width="600" />

å½“ç„¶ï¼Œé’ˆå¯¹ä¸åŒä¸šåŠ¡åœºæ™¯ï¼Œè¿™äº›é—®é¢˜å¹¶ä¸ä¸€å®šå…¨éƒ¨å­˜åœ¨ï¼Œæ¯”å¦‚æ‹¼éŸ³è¾“å…¥æ³•ã€è¯­éŸ³è¯†åˆ«æ ¡å¯¹å…³æ³¨éŸ³ä¼¼é”™è¯¯ï¼›äº”ç¬”è¾“å…¥æ³•ã€OCRæ ¡å¯¹å…³æ³¨å½¢ä¼¼é”™è¯¯ï¼Œ
æœç´¢å¼•æ“queryçº é”™å…³æ³¨æ‰€æœ‰é”™è¯¯ç±»å‹ã€‚

æœ¬é¡¹ç›®é‡ç‚¹è§£å†³å…¶ä¸­çš„"éŸ³ä¼¼ã€å½¢å­—ã€è¯­æ³•ã€ä¸“åé”™è¯¯"ç­‰ç±»å‹ã€‚

# Features

* [Kenlmæ¨¡å‹](pycorrector/corrector.py)ï¼šæœ¬é¡¹ç›®åŸºäºKenlmç»Ÿè®¡è¯­è¨€æ¨¡å‹å·¥å…·è®­ç»ƒäº†ä¸­æ–‡NGramè¯­è¨€æ¨¡å‹ï¼Œç»“åˆè§„åˆ™æ–¹æ³•ã€æ··æ·†é›†å¯ä»¥çº æ­£ä¸­æ–‡æ‹¼å†™é”™è¯¯ï¼Œæ–¹æ³•é€Ÿåº¦å¿«ï¼Œæ‰©å±•æ€§å¼ºï¼Œæ•ˆæœä¸€èˆ¬
* [DeepContextæ¨¡å‹](pycorrector/deepcontext)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºæ–‡æœ¬çº é”™çš„DeepContextæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“æ„å‚è€ƒStanford Universityçš„NLCæ¨¡å‹ï¼Œ2014è‹±æ–‡çº é”™æ¯”èµ›å¾—ç¬¬ä¸€åï¼Œæ•ˆæœä¸€èˆ¬
* [Seq2Seqæ¨¡å‹](pycorrector/seq2seq)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„ConvSeq2Seqæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨NLPCC-2018çš„ä¸­æ–‡è¯­æ³•çº é”™æ¯”èµ›ä¸­ï¼Œä½¿ç”¨å•æ¨¡å‹å¹¶å–å¾—ç¬¬ä¸‰åï¼Œå¯ä»¥å¹¶è¡Œè®­ç»ƒï¼Œæ¨¡å‹æ”¶æ•›å¿«ï¼Œæ•ˆæœä¸€èˆ¬
* [T5æ¨¡å‹](pycorrector/t5)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„T5æ¨¡å‹ï¼Œä½¿ç”¨Langboat/mengzi-t5-baseçš„é¢„è®­ç»ƒæ¨¡å‹finetuneä¸­æ–‡çº é”™æ•°æ®é›†ï¼Œæ¨¡å‹æ”¹é€ çš„æ½œåŠ›è¾ƒå¤§ï¼Œæ•ˆæœå¥½
* [ERNIE_CSCæ¨¡å‹](pycorrector/ernie_csc)ï¼šæœ¬é¡¹ç›®åŸºäºPaddlePaddleå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„ERNIE_CSCæ¨¡å‹ï¼Œæ¨¡å‹åœ¨ERNIE-1.0ä¸Šfinetuneï¼Œæ¨¡å‹ç»“æ„é€‚é…äº†ä¸­æ–‡æ‹¼å†™çº é”™ä»»åŠ¡ï¼Œæ•ˆæœå¥½
* [MacBERTæ¨¡å‹](pycorrector/macbert)ã€æ¨èã€‘ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„MacBERT4CSCæ¨¡å‹ï¼Œæ¨¡å‹åŠ å…¥äº†é”™è¯¯æ£€æµ‹å’Œçº æ­£ç½‘ç»œï¼Œé€‚é…ä¸­æ–‡æ‹¼å†™çº é”™ä»»åŠ¡ï¼Œæ•ˆæœå¥½
* [GPTæ¨¡å‹](pycorrector/gpt)ã€æ¨èã€‘ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†ç”¨äºä¸­æ–‡æ–‡æœ¬çº é”™çš„ChatGLM/LLaMAæ¨¡å‹ï¼Œæ¨¡å‹åœ¨ä¸­æ–‡CSCå’Œè¯­æ³•çº é”™æ•°æ®é›†ä¸Šfinetuneï¼Œé€‚é…ä¸­æ–‡æ–‡æœ¬çº é”™ä»»åŠ¡ï¼Œæ•ˆæœå¥½

- å»¶å±•é˜…è¯»ï¼š[ä¸­æ–‡æ–‡æœ¬çº é”™å®è·µå’ŒåŸç†è§£è¯»](https://github.com/shibing624/pycorrector/blob/master/docs/correction_solution.md)
# Demo

Official Demo: https://www.mulanai.com/product/corrector/

HuggingFace Demo: https://huggingface.co/spaces/shibing624/pycorrector

![](docs/hf.png)

run example: [examples/gradio_demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/gradio_demo.py) to see the demo:
```shell
python examples/gradio_demo.py
```

# Evaluation

æä¾›è¯„ä¼°è„šæœ¬[examples/evaluate_models.py](https://github.com/shibing624/pycorrector/blob/master/examples/evaluate_models.py)ï¼š

- ä½¿ç”¨sighan15è¯„ä¼°é›†ï¼šSIGHAN2015çš„æµ‹è¯•é›†[pycorrector/data/sighan_2015/test.tsv](https://github.com/shibing624/pycorrector/blob/master/pycorrector/data/sighan_2015/test.tsv)
  ï¼Œå·²ç»è½¬ä¸ºç®€ä½“ä¸­æ–‡ã€‚
- è¯„ä¼°æ ‡å‡†ï¼šçº é”™å‡†å¬ç‡ï¼Œé‡‡ç”¨ä¸¥æ ¼å¥å­ç²’åº¦ï¼ˆSentence Levelï¼‰è®¡ç®—æ–¹å¼ï¼ŒæŠŠæ¨¡å‹çº æ­£ä¹‹åçš„ä¸æ­£ç¡®å¥å­å®Œæˆç›¸åŒçš„è§†ä¸ºæ­£ç¡®ï¼Œå¦åˆ™ä¸ºé”™ã€‚

### è¯„ä¼°ç»“æœ
è¯„ä¼°æ•°æ®é›†ï¼šSIGHAN2015æµ‹è¯•é›†

GPUï¼šTesla V100ï¼Œæ˜¾å­˜ 32 GB

| Model Name      | Model Hub Link                                                                                                      | Backbone                 | GPU | Precision | Recall | F1 | QPS     |
|:----------------|:--------------------------------------------------------------------------------------------------------------------|:-------------------------|:----|:----------| :--| :--- |:--------|
| Kenlm           | -                                                                                                                   | kenlm                    | CPU | 0.6860    | 0.1529 | 0.2500 | 9       |
| BART-CSC        | [shibing624/bart4csc-base-chinese](https://huggingface.co/shibing624/bart4csc-base-chinese)                         | fnlp/bart-base-chinese   | GPU | 0.6984    | 0.6354 | 0.6654 | 58      |
| Mengzi-T5-CSC   | [shibing624/mengzi-t5-base-chinese-correction](https://huggingface.co/shibing624/mengzi-t5-base-chinese-correction) | mengzi-t5-base           | GPU | **0.8321**    | 0.6390 | 0.7229 | 214     |
| **MacBERT-CSC** | [shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)                   | hfl/chinese-macbert-base | GPU | 0.8254  | **0.7311** | **0.7754** | **224** |
| ChatGLM3-6B-CSC | [shibing624/chatglm3-6b-csc-chinese-lora](https://huggingface.co/shibing624/chatglm3-6b-csc-chinese-lora)           | chatglm3-6b              | GPU | 0.5263    | 0.4052 | 0.4579 | 4       |

### ç»“è®º

- ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹æ•ˆæœæœ€å¥½çš„æ˜¯**MacBert-CSC**ï¼Œæ¨¡å‹åç§°æ˜¯*shibing624/macbert4csc-base-chinese*ï¼Œhuggingface modelï¼š[shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)
- ä¸­æ–‡è¯­æ³•çº é”™æ¨¡å‹æ•ˆæœæœ€å¥½çš„æ˜¯**ChatGLM3-6B-CSC**ï¼Œæ¨¡å‹åç§°æ˜¯*shibing624/chatglm3-6b-csc-chinese-lora*ï¼Œhuggingface modelï¼š[shibing624/shibing624/chatglm3-6b-csc-chinese-lora](https://huggingface.co/shibing624/shibing624/chatglm3-6b-csc-chinese-lora)

# Install

```shell
pip install -U pycorrector
```

or

```shell
pip install -r requirements.txt

git clone https://github.com/shibing624/pycorrector.git
cd pycorrector
pip install --no-deps .
```


é€šè¿‡ä»¥ä¸Šä¸¤ç§æ–¹æ³•çš„ä»»ä½•ä¸€ç§å®Œæˆå®‰è£…éƒ½å¯ä»¥ã€‚å¦‚æœä¸æƒ³å®‰è£…ä¾èµ–åŒ…ï¼Œç›´æ¥ä½¿ç”¨dockeræ‹‰å–å®‰è£…å¥½çš„éƒ¨ç½²ç¯å¢ƒå³å¯ã€‚

#### å®‰è£…ä¾èµ–

* dockerä½¿ç”¨

```shell
docker run -it -v ~/.pycorrector:/root/.pycorrector shibing624/pycorrector:0.0.2
```

åç»­è°ƒç”¨pythonä½¿ç”¨å³å¯ï¼Œè¯¥é•œåƒå·²ç»å®‰è£…å¥½kenlmã€pycorrectorç­‰åŒ…ï¼Œå…·ä½“å‚è§[Dockerfile](Dockerfile)ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š

![docker](https://github.com/shibing624/pycorrector/blob/master/docs/git_image/docker.png)

* kenlmå®‰è£…

```
pip install kenlm
```

[å®‰è£…kenlm-wiki](https://github.com/shibing624/pycorrector/wiki/Install-kenlm)

* å…¶ä»–åº“åŒ…å®‰è£…

```
pip install -r requirements.txt
```

# Usage

## ç»Ÿè®¡æ¨¡å‹ï¼ˆkenlmï¼‰
### ä¸­æ–‡æ‹¼å†™çº é”™

example: [examples/kenlm/demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/demo.py)


```python
from pycorrector import Corrector
m = Corrector()
print(m.correct_batch(['å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å', 'ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å¿ƒã€‚']))
```

output:
```shell
[{'source': 'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å', 'target': 'å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§', 'errors': [('å› è¯¥', 'åº”è¯¥', 4), ('å', 'åº§', 10)]}
{'source': 'ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å¿ƒã€‚', 'target': 'ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å…´ã€‚', 'errors': [('å¿ƒ', 'å…´', 15)]}]
```

> è§„åˆ™æ–¹æ³•é»˜è®¤ä¼šä»è·¯å¾„`~/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm`åŠ è½½kenlmè¯­è¨€æ¨¡å‹æ–‡ä»¶ï¼Œå¦‚æœæ£€æµ‹æ²¡æœ‰è¯¥æ–‡ä»¶ï¼Œ
åˆ™ç¨‹åºä¼šè‡ªåŠ¨è”ç½‘ä¸‹è½½ã€‚å½“ç„¶ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½[æ¨¡å‹æ–‡ä»¶(2.8G)](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm)å¹¶æ”¾ç½®äºè¯¥ä½ç½®ã€‚

### é”™è¯¯æ£€æµ‹

example: [examples/kenlm/detect_demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/detect_demo.py)

```python
from pycorrector import Corrector
m = Corrector()
idx_errors = m.detect('å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å')
print(idx_errors)
```

output:

```
[['å› è¯¥', 4, 6, 'word'], ['å', 10, 11, 'char']]
```

> è¿”å›ç±»å‹æ˜¯`list`, `[error_word, begin_pos, end_pos, error_type]`ï¼Œ`pos`ç´¢å¼•ä½ç½®ä»¥0å¼€å§‹ã€‚

### æˆè¯­ã€ä¸“åçº é”™

example: [examples/kenlm/proper_correct_demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/proper_correct_demo.py)

```python
import sys

sys.path.append("..")
from pycorrector import ProperCorrector

m = ProperCorrector()
x = [
    'æŠ¥åº”æ¥ä¸­è¿©æ¥',
    'ä»Šå¤©åœ¨æ‹¼å“†å“†ä¸Šä¹°äº†ç‚¹è‹¹æœ',
]

for i in x:
    print(i, ' -> ', m.correct(i))
```

output:

```
æŠ¥åº”æ¥ä¸­è¿©æ¥  ->  {'source': 'æŠ¥åº”æ¥è¸µè€Œæ¥', 'target': 'æŠ¥åº”æ¥è¸µè€Œæ¥', 'errors': [('æ¥ä¸­è¿©æ¥', 'æ¥è¸µè€Œæ¥', 2)]}
è¿™å—åè¡¨å¸¦å¸¦ç›¸ä¼   ->  {'source': 'è¿™å—åè¡¨ä»£ä»£ç›¸ä¼ ', 'target': 'è¿™å—åè¡¨ä»£ä»£ç›¸ä¼ ', 'errors': [('å¸¦å¸¦ç›¸ä¼ ', 'ä»£ä»£ç›¸ä¼ ', 4)]}
```


### è‡ªå®šä¹‰æ··æ·†é›†

é€šè¿‡åŠ è½½è‡ªå®šä¹‰æ··æ·†é›†ï¼Œæ”¯æŒç”¨æˆ·çº æ­£å·²çŸ¥çš„é”™è¯¯ï¼ŒåŒ…æ‹¬ä¸¤æ–¹é¢åŠŸèƒ½ï¼š1ï¼‰ã€æå‡å‡†ç¡®ç‡ã€‘è¯¯æ€åŠ ç™½ï¼›2ï¼‰ã€æå‡å¬å›ç‡ã€‘è¡¥å……å¬å›ã€‚

example: [examples/kenlm/use_custom_confusion.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/use_custom_confusion.py)

```python
from pycorrector import ConfusionCorrector, Corrector

error_sentences = [
    'ä¹°iphonexï¼Œè¦å¤šå°‘é’±',
    'å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ æ——åº·',
]
m = Corrector()
print(m.correct_batch(error_sentences))
print('*' * 42)
m = ConfusionCorrector(custom_confusion_path_or_dict='./my_custom_confusion.txt')
print(m.correct_batch(error_sentences))
```

output:

```
('ä¹°iphonexï¼Œè¦å¤šå°‘é’±', [])   # "iphonex"æ¼å¬ï¼Œåº”è¯¥æ˜¯"iphoneX"
('å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ å¯åº·', [['å¼ æ——åº·', 'å¼ å¯åº·', 14, 17]]) # "å¼ å¯åº·"è¯¯æ€ï¼Œåº”è¯¥ä¸ç”¨çº 
*****************************************************
('ä¹°iphonexï¼Œè¦å¤šå°‘é’±', [['iphonex', 'iphoneX', 1, 8]])
('å…±åŒå®é™…æ§åˆ¶äººè§åã€éœè£é“¨ã€å¼ æ——åº·', [])
```

> å…¶ä¸­`./my_custom_confusion.txt`çš„å†…å®¹æ ¼å¼å¦‚ä¸‹ï¼Œä»¥ç©ºæ ¼é—´éš”ï¼š

```
iPhoneå·® iPhoneX
å¼ æ——åº· å¼ æ——åº·
```

> æ··æ·†é›†åŠŸèƒ½åœ¨`correct`æ–¹æ³•ä¸­ç”Ÿæ•ˆï¼›
> `set_custom_confusion_dict`æ–¹æ³•çš„`path`å‚æ•°ä¸ºç”¨æˆ·è‡ªå®šä¹‰æ··æ·†é›†æ–‡ä»¶è·¯å¾„(str)æˆ–æ··æ·†é›†å­—å…¸(dict)ã€‚

### è‡ªå®šä¹‰è¯­è¨€æ¨¡å‹

é»˜è®¤æä¾›ä¸‹è½½å¹¶ä½¿ç”¨çš„kenlmè¯­è¨€æ¨¡å‹`zh_giga.no_cna_cmn.prune01244.klm`æ–‡ä»¶æ˜¯2.8Gï¼Œå†…å­˜å°çš„ç”µè„‘ä½¿ç”¨`pycorrector`ç¨‹åºå¯èƒ½ä¼šåƒåŠ›äº›ã€‚

æ”¯æŒç”¨æˆ·åŠ è½½è‡ªå·±è®­ç»ƒçš„kenlmè¯­è¨€æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨2014ç‰ˆäººæ°‘æ—¥æŠ¥æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œæ¨¡å‹å°ï¼ˆ140Mï¼‰ï¼Œå‡†ç¡®ç‡ç¨ä½ï¼Œæ¨¡å‹ä¸‹è½½åœ°å€ï¼š[people2014corpus_chars.klm(å¯†ç o5e9)](https://pan.baidu.com/s/1I2GElyHy_MAdek3YaziFYw)ã€‚

exampleï¼š[examples/kenlm/load_custom_language_model.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/load_custom_language_model.py)

```python
from pycorrector import Corrector
import os
pwd_path = os.path.abspath(os.path.dirname(__file__))
lm_path = os.path.join(pwd_path, './people2014corpus_chars.klm')
model = Corrector(language_model_path=lm_path)
print(model.correct('å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å'))
```

### è‹±æ–‡æ‹¼å†™çº é”™

æ”¯æŒè‹±æ–‡å•è¯çº§åˆ«çš„æ‹¼å†™é”™è¯¯çº æ­£ã€‚

exampleï¼š[examples/kenlm/en_correct_demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/en_correct_demo.py)

```python
from pycorrector import EnSpellCorrector
m = EnSpellCorrector()
sent = "what happending? how to speling it, can you gorrect it?"
print(m.correct(sent))
```

output:

```
{'source': 'what happending? how to speling it, can you gorrect it?', 'target': 'what happening? how to spelling it, can you correct it?', 'errors': [('happending', 'happening', 5), ('speling', 'spelling', 24), ('gorrect', 'correct', 44)]}
```

### ä¸­æ–‡ç®€ç¹äº’æ¢

æ”¯æŒä¸­æ–‡ç¹ä½“åˆ°ç®€ä½“çš„è½¬æ¢ï¼Œå’Œç®€ä½“åˆ°ç¹ä½“çš„è½¬æ¢ã€‚

exampleï¼š[examples/kenlm/traditional_simplified_chinese_demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/kenlm/traditional_simplified_chinese_demo.py)

```python
import pycorrector

traditional_sentence = 'æ†‚éƒçš„è‡ºç£çƒé¾œ'
simplified_sentence = pycorrector.traditional2simplified(traditional_sentence)
print(traditional_sentence, '=>', simplified_sentence)

simplified_sentence = 'å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ'
traditional_sentence = pycorrector.simplified2traditional(simplified_sentence)
print(simplified_sentence, '=>', traditional_sentence)
```

output:

```
æ†‚éƒçš„è‡ºç£çƒé¾œ => å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ
å¿§éƒçš„å°æ¹¾ä¹Œé¾Ÿ => æ†‚éƒçš„è‡ºç£çƒé¾œ
```

### å‘½ä»¤è¡Œæ¨¡å¼

æ”¯æŒæ‰¹é‡æ–‡æœ¬çº é”™

```
python -m pycorrector -h
usage: __main__.py [-h] -o OUTPUT [-n] [-d] input

@description:

positional arguments:
  input                 the input file path, file encode need utf-8.

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT, --output OUTPUT
                        the output file path.
  -n, --no_char         disable char detect mode.
  -d, --detail          print detail info
```

caseï¼š

```
python -m pycorrector input.txt -o out.txt -n -d
```

> è¾“å…¥æ–‡ä»¶ï¼š`input.txt`ï¼›è¾“å‡ºæ–‡ä»¶ï¼š`out.txt `ï¼›å…³é—­å­—ç²’åº¦çº é”™ï¼›æ‰“å°è¯¦ç»†çº é”™ä¿¡æ¯ï¼›çº é”™ç»“æœä»¥`\t`é—´éš”

## Deep Model for Text Correction

æœ¬é¡¹ç›®çš„åˆè¡·ä¹‹ä¸€æ˜¯æ¯”å¯¹ã€å…±äº«å„ç§æ–‡æœ¬çº é”™æ–¹æ³•ï¼ŒæŠ›ç –å¼•ç‰çš„ä½œç”¨ï¼Œå¦‚æœå¯¹å¤§å®¶åœ¨æ–‡æœ¬çº é”™ä»»åŠ¡ä¸Šæœ‰ä¸€ç‚¹å°å°çš„å¯å‘å°±æ˜¯æˆ‘è«å¤§çš„è£å¹¸äº†ã€‚

å®ç°äº†macbertã€seq2seqã€ ernie_cscã€T5ã€deepcontextã€GPTæ·±åº¦æ¨¡å‹åº”ç”¨äºæ–‡æœ¬çº é”™ä»»åŠ¡ã€‚

- å®‰è£…ä¾èµ–

```
pip install -r requirements-dev.txt
```

## ä½¿ç”¨æ–¹æ³•

å„æ¨¡å‹å‡å¯ç‹¬ç«‹çš„åŸºäºè‡ªæœ‰æ•°æ®è®­ç»ƒã€é¢„æµ‹ã€‚

### **MacBert4cscæ¨¡å‹[æ¨è]**

åŸºäºMacBERTæ”¹å˜ç½‘ç»œç»“æ„çš„ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹ï¼Œæ¨¡å‹å·²ç»å¼€æºåœ¨HuggingFace Modelsï¼š[https://huggingface.co/shibing624/macbert4csc-base-chinese](https://huggingface.co/shibing624/macbert4csc-base-chinese)

æ¨¡å‹ç½‘ç»œç»“æ„ï¼š
- æœ¬é¡¹ç›®æ˜¯ MacBERT æ”¹å˜ç½‘ç»œç»“æ„çš„ä¸­æ–‡æ–‡æœ¬çº é”™æ¨¡å‹ï¼Œå¯æ”¯æŒ BERT ç±»æ¨¡å‹ä¸º backboneã€‚
- åœ¨åŸç”Ÿ BERT æ¨¡å‹ä¸Šè¿›è¡Œäº†é­”æ”¹ï¼Œè¿½åŠ äº†ä¸€ä¸ªå…¨è¿æ¥å±‚ä½œä¸ºé”™è¯¯æ£€æµ‹å³ [detection](https://github.com/shibing624/pycorrector/blob/c0f31222b7849c452cc1ec207c71e9954bd6ca08/pycorrector/macbert/macbert4csc.py#L18) ï¼Œ
MacBERT4CSC è®­ç»ƒæ—¶ç”¨ detection å±‚å’Œ correction å±‚çš„ loss åŠ æƒå¾—åˆ°æœ€ç»ˆçš„ lossã€‚é¢„æµ‹æ—¶ç”¨ BERT MLM çš„ correction æƒé‡å³å¯ã€‚ 

![macbert_network](https://github.com/shibing624/pycorrector/blob/master/docs/git_image/macbert_network.jpg)

è¯¦ç»†æ•™ç¨‹å‚è€ƒ[examples/macbert/README.md](https://github.com/shibing624/pycorrector/blob/master/examples/macbert/README.md)


#### ä½¿ç”¨pycorrectorå¿«é€Ÿé¢„æµ‹
exampleï¼š[examples/macbert/demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/macbert/demo.py)

```python
import sys

sys.path.append("..")
from pycorrector import MacBertCorrector

if __name__ == '__main__':
    error_sentences = [
        'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ— ',
        'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å',
        'æœºä¸ƒå­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†é‡æœ€èƒ½ä½“ç°æ™ºèƒ½çš„ä¸€ä¸ªåˆ†çŸ¥',
        'ä¸€åªå°é±¼èˆ¹æµ®åœ¨å¹³å‡€çš„æ²³é¢ä¸Š',
        'æˆ‘çš„å®¶ä¹¡æ˜¯æœ‰æ˜çš„æ¸”ç±³ä¹‹ä¹¡',
    ]

    m = MacBertCorrector("shibing624/macbert4csc-base-chinese")
    batch_res = m.correct_batch(error_sentences)
    for i in batch_res:
        print(i)
        print()
```

outputï¼š

```bash
{'source': 'ä»Šå¤©æ–°æƒ…å¾ˆå¥½', 'target': 'ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½', 'errors': [('æ–°', 'å¿ƒ', 2)]}
{'source': 'ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å¿ƒã€‚', 'target': 'ä½ æ‰¾åˆ°ä½ æœ€å–œæ¬¢çš„å·¥ä½œï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å…´ã€‚', 'errors': [('å¿ƒ', 'å…´', 15)]}
```

#### ä½¿ç”¨åŸç”Ÿtransformersåº“å¿«é€Ÿé¢„æµ‹
è§[examples/macbert/README.md](https://github.com/shibing624/pycorrector/blob/master/examples/macbert/README.md)

### ErnieCSCæ¨¡å‹

åŸºäºERNIEçš„ä¸­æ–‡æ‹¼å†™çº é”™æ¨¡å‹ï¼Œæ¨¡å‹å·²ç»å¼€æºåœ¨[PaddleNLP](https://bj.bcebos.com/paddlenlp/taskflow/text_correction/csc-ernie-1.0/csc-ernie-1.0.pdparams)ã€‚
æ¨¡å‹ç½‘ç»œç»“æ„ï¼š

<img src="https://user-images.githubusercontent.com/10826371/131974040-fc84ec04-566f-4310-9839-862bfb27172e.png" width="500" />

è¯¦ç»†æ•™ç¨‹å‚è€ƒ[examples/ernie_csc/README.md](https://github.com/shibing624/pycorrector/blob/master/examples/ernie_csc/README.md)



#### ä½¿ç”¨pycorrectorå¿«é€Ÿé¢„æµ‹
exampleï¼š[examples/ernie_csc/demo.py](https://github.com/shibing624/pycorrector/blob/master/examples/ernie_csc/demo.py)
```python
from pycorrector import ErnieCscCorrector

if __name__ == '__main__':
    error_sentences = [
        'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ— ',
        'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å',
    ]
    m = ErnieCscCorrector()
    batch_res = m.correct_batch(error_sentences)
    for i in batch_res:
        print(i)
        print()
```

output:

```
{'source': 'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³æ— ', 'target': 'çœŸéº»çƒ¦ä½ äº†ã€‚å¸Œæœ›ä½ ä»¬å¥½å¥½çš„è·³èˆ', 'errors': [{'position': 14, 'correction': {'æ— ': 'èˆ'}}]}
{'source': 'å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å', 'target': 'å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§', 'errors': [{'position': 4, 'correction': {'å› ': 'åº”'}}, {'position': 10, 'correction': {'å': 'åº§'}}]}
```


### Bartæ¨¡å‹

```python
from transformers import BertTokenizerFast
from textgen import BartSeq2SeqModel

tokenizer = BertTokenizerFast.from_pretrained('shibing624/bart4csc-base-chinese')
model = BartSeq2SeqModel(
    encoder_type='bart',
    encoder_decoder_type='bart',
    encoder_decoder_name='shibing624/bart4csc-base-chinese',
    tokenizer=tokenizer,
    args={"max_length": 128, "eval_batch_size": 128})
sentences = ["å°‘å…ˆé˜Ÿå‘˜å› è¯¥ä¸ºè€äººè®©å"]
print(model.predict(sentences))
```

output:
```shell
['å°‘å…ˆé˜Ÿå‘˜åº”è¯¥ä¸ºè€äººè®©åº§']
```

å¦‚æœéœ€è¦è®­ç»ƒBartæ¨¡å‹ï¼Œè¯·å‚è€ƒ https://github.com/shibing624/textgen/blob/main/examples/seq2seq/training_bartseq2seq_zh_demo.py

#### Release models

åŸºäºSIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†è®­ç»ƒçš„Bartæ¨¡å‹ï¼Œå·²ç»releaseåˆ°HuggingFace Models: [https://huggingface.co/shibing624/bart4csc-base-chinese](https://huggingface.co/shibing624/bart4csc-base-chinese)

# Dataset

| æ•°æ®é›†                          | è¯­æ–™ |                                                                                ä¸‹è½½é“¾æ¥                                                                                 | å‹ç¼©åŒ…å¤§å° |
|:-----------------------------| :--------- |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----:|
| **`SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†`** | SIGHAN+Wang271K(27ä¸‡æ¡) |               [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç 01b9ï¼‰](https://pan.baidu.com/s/1BV5tr9eONZCI0wERFvr0gQ) <br/> [shibing624/CSC](https://huggingface.co/datasets/shibing624/CSC)                | 106M  |
| **`åŸå§‹SIGHANæ•°æ®é›†`**            | SIGHAN13 14 15 |                                                      [å®˜æ–¹csc.html](http://nlp.ee.ncu.edu.tw/resource/csc.html)                                                       | 339K  |
| **`åŸå§‹Wang271Kæ•°æ®é›†`**          | Wang271K |                   [Automatic-Corpus-Generation dimmywangæä¾›](https://github.com/wdimmy/Automatic-Corpus-Generation/blob/master/corpus/train.sgml)                    |  93M  |
| **`äººæ°‘æ—¥æŠ¥2014ç‰ˆè¯­æ–™`**            | äººæ°‘æ—¥æŠ¥2014ç‰ˆ |                                    [é£ä¹¦ï¼ˆå¯†ç cHcuï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcnKpildqIseq1D4IrLwlir7c?from=from_qr_code)                                    | 383M  |
| **`NLPCC 2018 GECå®˜æ–¹æ•°æ®é›†`**    | NLPCC2018-GEC |                                        [å®˜æ–¹trainingdata](http://tcci.ccf.org.cn/conference/2018/dldoc/trainingdata02.tar.gz)                                         | 114M  |
| **`NLPCC 2018+HSKç†Ÿè¯­æ–™`**      | nlpcc2018+hsk+CGED | [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç m6fgï¼‰](https://pan.baidu.com/s/1BkDru60nQXaDVLRSr7ktfA) <br/> [é£ä¹¦ï¼ˆå¯†ç gl9yï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcnudJgRs5GEMhZwe77YGTQfc?from=from_qr_code) | 215M  |
| **`NLPCC 2018+HSKåŸå§‹è¯­æ–™`**     | HSK+Lang8 | [ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç n31jï¼‰](https://pan.baidu.com/s/1DaOX89uL1JRaZclfrV9C0g) <br/> [é£ä¹¦ï¼ˆå¯†ç Q9LHï¼‰](https://l6pmn3b1eo.feishu.cn/file/boxcntebW3NI6OAaqzDUXlZHoDb?from=from_qr_code) |  81M  |
| **`ä¸­æ–‡çº é”™æ¯”èµ›æ•°æ®æ±‡æ€»`**             | Chinese Text Correctionï¼ˆCTCï¼‰ |                                                     [ä¸­æ–‡çº é”™æ±‡æ€»æ•°æ®é›†ï¼ˆå¤©æ± ï¼‰](https://tianchi.aliyun.com/dataset/138195)                                                      |   -   |
| **`NLPCC 2023ä¸­æ–‡è¯­æ³•çº é”™æ•°æ®é›†`**    | NLPCC 2023 Sharedtask1 |                          [Task 1: Chinese Grammatical Error Correctionï¼ˆTraining Setï¼‰](http://tcci.ccf.org.cn/conference/2023/taskdata.php)                          | 125M  |



è¯´æ˜ï¼š

- SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†(27ä¸‡æ¡)ï¼Œæ˜¯é€šè¿‡åŸå§‹SIGHAN13ã€14ã€15å¹´æ•°æ®é›†å’ŒWang271Kæ•°æ®é›†æ ¼å¼è½¬åŒ–åå¾—åˆ°ï¼Œjsonæ ¼å¼ï¼Œå¸¦é”™è¯¯å­—ç¬¦ä½ç½®ä¿¡æ¯ï¼ŒSIGHANä¸ºtest.jsonï¼Œ
  macbert4cscæ¨¡å‹è®­ç»ƒå¯ä»¥ç›´æ¥ç”¨è¯¥æ•°æ®é›†å¤ç°paperå‡†å¬ç»“æœï¼Œè¯¦è§[pycorrector/macbert/README.md](pycorrector/macbert/README.md)ã€‚
- NLPCC 2018 GECå®˜æ–¹æ•°æ®é›†[NLPCC2018-GEC](http://tcci.ccf.org.cn/conference/2018/taskdata.php)ï¼Œ
  è®­ç»ƒé›†[trainingdata](http://tcci.ccf.org.cn/conference/2018/dldoc/trainingdata02.tar.gz)[è§£å‹å114.5MB]ï¼Œè¯¥æ•°æ®æ ¼å¼æ˜¯åŸå§‹æ–‡æœ¬ï¼Œæœªåšåˆ‡è¯å¤„ç†ã€‚
- æ±‰è¯­æ°´å¹³è€ƒè¯•ï¼ˆHSKï¼‰å’Œlang8åŸå§‹å¹³è¡Œè¯­æ–™[HSK+Lang8][ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç n31jï¼‰](https://pan.baidu.com/s/1DaOX89uL1JRaZclfrV9C0g)ï¼Œè¯¥æ•°æ®é›†å·²ç»åˆ‡è¯ï¼Œå¯ç”¨ä½œæ•°æ®æ‰©å¢ã€‚
- NLPCC 2018 + HSK + CGED16ã€17ã€18çš„æ•°æ®ï¼Œç»è¿‡ä»¥å­—åˆ‡åˆ†ï¼Œç¹ä½“è½¬ç®€ä½“ï¼Œæ‰“ä¹±æ•°æ®é¡ºåºçš„é¢„å¤„ç†åï¼Œç”Ÿæˆç”¨äºçº é”™çš„ç†Ÿè¯­æ–™(nlpcc2018+hsk)
  ï¼Œ[ç™¾åº¦ç½‘ç›˜ï¼ˆå¯†ç :m6fgï¼‰](https://pan.baidu.com/s/1BkDru60nQXaDVLRSr7ktfA) [130ä¸‡å¯¹å¥å­ï¼Œ215MB]

SIGHAN+Wang271Kä¸­æ–‡çº é”™æ•°æ®é›†ï¼Œæ•°æ®æ ¼å¼ï¼š
```json
[
    {
        "id": "B2-4029-3",
        "original_text": "æ™šé—´ä¼šå¬åˆ°å—“éŸ³ï¼Œç™½å¤©çš„æ—¶å€™å¤§å®¶éƒ½ä¸ä¼šå¤ªåœ¨æ„ï¼Œä½†æ˜¯åœ¨ç¡è§‰çš„æ—¶å€™è¿™å—“éŸ³æˆä¸ºå¤§å®¶çš„æ¶æ¢¦ã€‚",
        "wrong_ids": [
            5,
            31
        ],
        "correct_text": "æ™šé—´ä¼šå¬åˆ°å™ªéŸ³ï¼Œç™½å¤©çš„æ—¶å€™å¤§å®¶éƒ½ä¸ä¼šå¤ªåœ¨æ„ï¼Œä½†æ˜¯åœ¨ç¡è§‰çš„æ—¶å€™è¿™å™ªéŸ³æˆä¸ºå¤§å®¶çš„æ¶æ¢¦ã€‚"
    }
]
```

å­—æ®µè§£é‡Šï¼š
- idï¼šå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œæ— æ„ä¹‰
- original_text: åŸå§‹é”™è¯¯æ–‡æœ¬
- wrong_idsï¼š é”™è¯¯å­—çš„ä½ç½®ï¼Œä»0å¼€å§‹
- correct_text: çº æ­£åçš„æ–‡æœ¬

#### è‡ªæœ‰æ•°æ®é›†

å¯ä»¥ä½¿ç”¨è‡ªå·±æ•°æ®é›†è®­ç»ƒçº é”™æ¨¡å‹ï¼ŒæŠŠè‡ªå·±æ•°æ®é›†æ ‡æ³¨å¥½ï¼Œä¿å­˜ä¸ºè·Ÿè®­ç»ƒæ ·æœ¬é›†ä¸€æ ·çš„jsonæ ¼å¼ï¼Œç„¶ååŠ è½½æ•°æ®è®­ç»ƒæ¨¡å‹å³å¯ã€‚

1. å·²æœ‰å¤§é‡ä¸šåŠ¡ç›¸å…³é”™è¯¯æ ·æœ¬ï¼Œä¸»è¦æ ‡æ³¨é”™è¯¯ä½ç½®ï¼ˆwrong_idsï¼‰å’Œçº é”™åçš„å¥å­(correct_text)
2. æ²¡æœ‰ç°æˆçš„é”™è¯¯æ ·æœ¬ï¼Œå¯ä»¥å†™è„šæœ¬ç”Ÿæˆé”™è¯¯æ ·æœ¬ï¼ˆoriginal_textï¼‰ï¼Œæ ¹æ®éŸ³ä¼¼ã€å½¢ä¼¼ç­‰ç‰¹å¾æŠŠæ­£ç¡®å¥å­çš„æŒ‡å®šä½ç½®ï¼ˆwrong_idsï¼‰å­—ç¬¦æ”¹ä¸ºé”™å­—ï¼Œé™„ä¸Š
ç¬¬ä¸‰æ–¹åŒéŸ³å­—ç”Ÿæˆè„šæœ¬[åŒéŸ³è¯æ›¿æ¢](https://github.com/dongrixinyu/JioNLP/wiki/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3#%E5%90%8C%E9%9F%B3%E8%AF%8D%E6%9B%BF%E6%8D%A2)


## Language Model

[ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ-wiki](https://github.com/shibing624/pycorrector/wiki/%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86)

è¯­è¨€æ¨¡å‹å¯¹äºçº é”™æ­¥éª¤è‡³å…³é‡è¦ï¼Œå½“å‰é»˜è®¤ä½¿ç”¨çš„æ˜¯ä»åƒå…†ä¸­æ–‡æ–‡æœ¬è®­ç»ƒçš„ä¸­æ–‡è¯­è¨€æ¨¡å‹[zh_giga.no_cna_cmn.prune01244.klm(2.8G)](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm)ï¼Œ
æä¾›äººæ°‘æ—¥æŠ¥2014ç‰ˆè¯­æ–™è®­ç»ƒå¾—åˆ°çš„è½»é‡ç‰ˆè¯­è¨€æ¨¡å‹[people2014corpus_chars.klm(å¯†ç o5e9)](https://pan.baidu.com/s/1I2GElyHy_MAdek3YaziFYw)ã€‚

å¤§å®¶å¯ä»¥ç”¨ä¸­æ–‡ç»´åŸºï¼ˆç¹ä½“è½¬ç®€ä½“ï¼Œpycorrector.utils.text_utilsä¸‹æœ‰æ­¤åŠŸèƒ½ï¼‰ç­‰è¯­æ–™æ•°æ®è®­ç»ƒé€šç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ç”¨ä¸“ä¸šé¢†åŸŸè¯­æ–™è®­ç»ƒæ›´ä¸“ç”¨çš„è¯­è¨€æ¨¡å‹ã€‚æ›´é€‚ç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œå¯¹äºçº é”™æ•ˆæœä¼šæœ‰æ¯”è¾ƒå¥½çš„æå‡ã€‚

1. kenlmè¯­è¨€æ¨¡å‹è®­ç»ƒå·¥å…·çš„ä½¿ç”¨ï¼Œè¯·è§åšå®¢ï¼šhttp://blog.csdn.net/mingzai624/article/details/79560063
2. é™„ä¸Šè®­ç»ƒè¯­æ–™<äººæ°‘æ—¥æŠ¥2014ç‰ˆç†Ÿè¯­æ–™>ï¼ŒåŒ…æ‹¬ï¼š 1ï¼‰æ ‡å‡†äººå·¥åˆ‡è¯åŠè¯æ€§æ•°æ®people2014.tar.gzï¼Œ 2ï¼‰æœªåˆ‡è¯æ–‡æœ¬æ•°æ®people2014_words.txtï¼Œ
   3ï¼‰kenlmè®­ç»ƒå­—ç²’åº¦è¯­è¨€æ¨¡å‹æ–‡ä»¶åŠå…¶äºŒè¿›åˆ¶æ–‡ä»¶people2014corpus_chars.arps/klmï¼Œ 4ï¼‰kenlmè¯ç²’åº¦è¯­è¨€æ¨¡å‹æ–‡ä»¶åŠå…¶äºŒè¿›åˆ¶æ–‡ä»¶people2014corpus_words.arps/klmã€‚

- 16GBä¸­è‹±æ–‡æ— ç›‘ç£ã€å¹³è¡Œè¯­æ–™[Linly-AI/Chinese-pretraining-dataset](https://huggingface.co/datasets/Linly-AI/Chinese-pretraining-dataset)
- 524MBä¸­æ–‡ç»´åŸºç™¾ç§‘è¯­æ–™[wikipedia-cn-20230720-filtered](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)

å°Šé‡ç‰ˆæƒï¼Œä¼ æ’­è¯·æ³¨æ˜å‡ºå¤„ã€‚


# Contact

- Github Issue(å»ºè®®)ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/issues)
- Github discussionsï¼šæ¬¢è¿åˆ°è®¨è®ºåŒº[![GitHub discussions](https://img.shields.io/github/discussions/shibing624/pycorrector.svg)](https://github.com/shibing624/pycorrector/discussions)çŒæ°´ï¼ˆä¸ä¼šæ‰“æ‰°å¼€å‘è€…ï¼‰ï¼Œå…¬å¼€äº¤æµçº é”™æŠ€æœ¯å’Œé—®é¢˜
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼šåŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624*, è¿›Python-NLPäº¤æµç¾¤ï¼Œå¤‡æ³¨ï¼š*å§“å-å…¬å¸å-NLP*


<img src="https://github.com/shibing624/pycorrector/blob/master/docs/git_image/wechat.jpeg" width="200" />

# Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†pycorrectorï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

APA:
```latex
Xu, M. Pycorrector: Text error correction tool (Version 0.4.2) [Computer software]. https://github.com/shibing624/pycorrector
```

BibTeX:
```latex
@misc{Xu_Pycorrector_Text_error,
  title={Pycorrector: Text error correction tool},
  author={Ming Xu},
  year={2021},
  howpublished={\url{https://github.com/shibing624/pycorrector}},
}
```



# License

pycorrector çš„æˆæƒåè®®ä¸º **Apache License 2.0**ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ pycorrectorçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚

# Contribute

é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

- åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
- ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚

# Reference

* [åŸºäºæ–‡æ³•æ¨¡å‹çš„ä¸­æ–‡çº é”™ç³»ç»Ÿ](https://blog.csdn.net/mingzai624/article/details/82390382)
* [Norvigâ€™s spelling corrector](http://norvig.com/spell-correct.html)
* [Chinese Spelling Error Detection and Correction Based on Language Model, Pronunciation, and Shape[Yu, 2013]](http://www.aclweb.org/anthology/W/W14/W14-6835.pdf)
* [Chinese Spelling Checker Based on Statistical Machine Translation[Chiu, 2013]](http://www.aclweb.org/anthology/O/O13/O13-1005.pdf)
* [Chinese Word Spelling Correction Based on Rule Induction[yeh, 2014]](http://aclweb.org/anthology/W14-6822)
* [Neural Language Correction with Character-Based Attention[Ziang Xie, 2016]](https://arxiv.org/pdf/1603.09727.pdf)
* [Chinese Spelling Check System Based on Tri-gram Model[Qiang Huang, 2014]](http://www.anthology.aclweb.org/W/W14/W14-6827.pdf)
* [Neural Abstractive Text Summarization with Sequence-to-Sequence Models[Tian Shi, 2018]](https://arxiv.org/abs/1812.02303)
* [åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ ¡å¯¹ç ”ç©¶ä¸å®ç°[æ¨å®—éœ–, 2019]](https://github.com/shibing624/pycorrector/blob/master/docs/åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ ¡å¯¹ç ”ç©¶ä¸å®ç°.pdf)
* [A Sequence to Sequence Learning for Chinese Grammatical Error Correction[Hongkai Ren, 2018]](https://link.springer.com/chapter/10.1007/978-3-319-99501-4_36)
* [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)
* [Revisiting Pre-trained Models for Chinese Natural Language Processing](https://arxiv.org/abs/2004.13922)
* Ruiqing Zhang, Chao Pang et al. "Correcting Chinese Spelling Errors with Phonetic Pre-training", ACL, 2021
* DingminWang et al. "A Hybrid Approach to Automatic Corpus Generation for Chinese Spelling Check", EMNLP, 2018
